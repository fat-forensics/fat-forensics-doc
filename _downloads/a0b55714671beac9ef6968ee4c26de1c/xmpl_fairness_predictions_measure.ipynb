{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Measuring Fairness of a Prediction -- Counterfactual Fairness\n\n\nThis example illustrates how scrutinise a data point under the counterfactual\nfairness assumption.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Kacper Sokol <k.sokol@bristol.ac.uk>\n# License: new BSD\n\nimport numpy as np\n\nimport fatf.utils.data.datasets as fatf_datasets\nimport fatf.utils.models as fatf_models\n\nimport fatf.fairness.predictions.measures as fatf_pfm\n\nimport fatf.transparency.predictions.counterfactuals as fatf_cf\n\nprint(__doc__)\n\n# Load data\nhr_data_dict = fatf_datasets.load_health_records()\nhr_X = hr_data_dict['data']\nhr_y = hr_data_dict['target']\nhr_feature_names = hr_data_dict['feature_names']\nhr_class_names = hr_data_dict['target_names']\n\n# Map target indices to target names\nhr_y = np.array([hr_class_names[i] for i in hr_y])\n\n# Drop the unique identifiers (features)\nunique_identifiers = ['name', 'email', 'zipcode', 'dob']\ncolumns_to_keep = [i for i in hr_X.dtype.names if i not in unique_identifiers]\n#\nhr_X = hr_X[columns_to_keep]\nhr_feature_names = [i for i in hr_feature_names if i not in unique_identifiers]\n\n# Train a model\nclf = fatf_models.KNN()\nclf.fit(hr_X, hr_y)\n\n# Select a data point to evaluate its counterfactual fairness\ndata_point_index = 4 + 2\ndata_point = hr_X[data_point_index]\ndata_point_y = hr_y[data_point_index]\n\n# Select a set of protected features\nprotected_features = ['gender', 'age']\n\n# Print out the protected features\nassert protected_features, 'The protected features list cannot be empty.'\nperson = ' is' if len(protected_features) == 1 else 's are'\nprint('The following fautre{} considered protected:'.format(person))\nfor feature_name in protected_features:\n    print('    * \"{}\".'.format(feature_name))\n\n# Print the instance\nprint('\\nEvaluating counterfactual fairness of a data point (index {}) of '\n      'class *{}* with the following features:'.format(data_point_index,\n                                                       data_point_y))\nfor feature_name in data_point.dtype.names:\n    print('    * The feature *{}* has value: {}.'.format(\n        feature_name, data_point[feature_name]))\n\n# Compute counterfactually unfair examples\ncfs, cfs_distances, cfs_classes = fatf_pfm.counterfactual_fairness(\n    instance=data_point,\n    protected_feature_indices=protected_features,\n    model=clf,\n    default_numerical_step_size=1,\n    dataset=hr_X)\n\n# Textualise possible counterfactually unfair data points\ncfs_text = fatf_cf.textualise_counterfactuals(\n    data_point,\n    cfs,\n    instance_class=data_point_y,\n    counterfactuals_distances=cfs_distances,\n    counterfactuals_predictions=cfs_classes)\nprint('\\n{}'.format(cfs_text))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}