{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Measuring Robustness of a Prediction -- Data Density\n\n\nThis example illustrates how to use a data density estimation to \"measure\" to\nwhat extent a prediction should be trusted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Kacper Sokol <k.sokol@bristol.ac.uk>\n# License: new BSD\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport fatf.utils.data.datasets as fatf_datasets\nimport fatf.utils.models as fatf_models\n\nimport fatf.utils.data.density as fatf_density\n\nprint(__doc__)\n\n# Prepare a colourmap\ncmap = np.array([\n    plt.get_cmap('Pastel1').colors[0],\n    plt.get_cmap('Pastel1').colors[1],\n    plt.get_cmap('Pastel1').colors[2]\n])\n\n# Load data\niris_data_dict = fatf_datasets.load_iris()\niris_X = iris_data_dict['data']\niris_y = iris_data_dict['target'].astype(int)\niris_feature_names = iris_data_dict['feature_names']\niris_class_names = iris_data_dict['target_names']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we visualise the data set based on two (arbitrarily chosen) features\nto help us guide choosing a data point in a sparse region and another one in\na dense region.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Choose 2 features\nchosen_features_index = [1, 2]\nchosen_features_name = iris_feature_names[chosen_features_index]\n\n# Get a subset of the data set with these two features\niris_X_chosen_features = iris_X[:, chosen_features_index]\n\n# Plot the dataset using the 2 selected features\nplt.scatter(\n    iris_X_chosen_features[:, 0], iris_X_chosen_features[:, 1], c=cmap[iris_y])\nplt.title('Iris data set scatter plot')\nplt.xlabel(chosen_features_name[0])\nplt.ylabel(chosen_features_name[1])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we train a predictive model on the whole data set using these two\nfeatures. We will use it to evaluate the quality and robustness of the\npredictions it provides.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Train a model\nclf = fatf_models.KNN()\nclf.fit(iris_X_chosen_features, iris_y)\n\n# Create two data points: one in a dense region and one in a sparse region\npoint_dense = np.array([[3.0, 5.0]])\npoint_sparse = np.array([[3.5, 3.25]])\n\n# Plot the dense and sparse data points\nplt.scatter(\n    iris_X_chosen_features[:, 0], iris_X_chosen_features[:, 1], c=cmap[iris_y])\nplt.scatter(\n    point_dense[:, 0],\n    point_dense[:, 1],\n    c='r',\n    s=200,\n    marker='X',\n    label='dense point')\nplt.scatter(\n    point_sparse[:, 0],\n    point_sparse[:, 1],\n    c='g',\n    s=200,\n    marker='X',\n    label='sparse point')\nplt.title('Dense and sparse data points visualisation')\nplt.xlabel(chosen_features_name[0])\nplt.ylabel(chosen_features_name[1])\nplt.legend(loc='upper right')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let us get the predictions for both these data points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Predict the two data points\npoint_dense_prediction = clf.predict(point_dense)[0]\npoint_sparse_prediction = clf.predict(point_sparse)[0]\n\n# Print out the predictions...\nprint('The **dense** data point is of class: {} ({}).'.format(\n    iris_class_names[point_dense_prediction], point_dense_prediction))\nprint('The **sparse** data point is of class: {} ({}).'.format(\n    iris_class_names[point_sparse_prediction], point_sparse_prediction))\n\n# ...and plot them with the class assignment\nplt.scatter(\n    iris_X_chosen_features[:, 0], iris_X_chosen_features[:, 1], c=cmap[iris_y])\nplt.scatter(\n    point_dense[:, 0],\n    point_dense[:, 1],\n    c=cmap[[int(point_dense_prediction)]],\n    s=200,\n    marker='X',\n    label='dense point -- {}'.format(iris_class_names[point_dense_prediction]))\nplt.scatter(\n    point_sparse[:, 0],\n    point_sparse[:, 1],\n    c=cmap[[int(point_sparse_prediction)]],\n    s=200,\n    marker='X',\n    label='sparse point -- {}'.format(\n        iris_class_names[point_sparse_prediction]))\nplt.title('Dense and sparse data points visualisation')\nplt.xlabel(chosen_features_name[0])\nplt.ylabel(chosen_features_name[1])\nplt.legend(loc='upper right')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we know how these two data points are distributed and what class\nis assigned to them by the classifier we can see how a **Data Density**\nscore can help us.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Print the class names for the probability vector\nprint('(The probability vector is based on the following class ordering: '\n      '{}.)\\n'.format(iris_class_names))\n\n# Initialise a density estimator\niris_density = fatf_density.DensityCheck(iris_X_chosen_features)\n\n# Get a denisty estimation for the dense point\ndensity_score_dense = iris_density.score_data_point(point_dense[0, :])\n# Get the probability predictions for the dense point\nprobabilities_dense = clf.predict_proba(point_dense)[0]\n\n# Get a denisty estimation for the sparse point\ndensity_score_sparse = iris_density.score_data_point(point_sparse[0, :])\n# Get the probability predictions for the sparse point\nprobabilities_sparse = clf.predict_proba(point_sparse)[0]\n\nprint('The prediction probabilities for the sparse data point are: {}, with a '\n      'density score of {}.'.format(probabilities_sparse,\n                                    density_score_sparse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above result clearly shows that despite the high probability -- 1 -- of\nthe *versicolor* class for the **sparse** data point, the prediction should\nnot be trusted. The high density score for that point -- 0.95 -- indicates\nthat this data point lies in a region of low density, therefore the\nclassifier has not seen many data points in this region, hence the model is\nsimply overconfident.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('The prediction probabilities for the dense data point are: {}, with a '\n      'density score of {}.'.format(probabilities_dense, density_score_dense))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On the other hand, the results for the **dense** data point, which the\nclassifier indicates to be of class *virginica* with 0.67 probability,\nshould be trusted given a low density score of 0.1. This data point\nclearly lies in a dense region, therefore the classifier has seen plenty\nof other data points in that region during the trainig procedure.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}