

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
  
    <title>fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime &#8212; FAT Forensics 0.0.2 documentation</title>
  <!-- html title is before nature.css - we use this hack to load bootstrap first -->
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css">

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="canonical" href="https://fat-forensics.org/generated/fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.html" />
    <link rel="shortcut icon" href="../_static/fatf.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree" href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.html" />
    <link rel="prev" title="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer" href="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.html" />
  <!-- jQuery first, then Bootstrap JS -->
  <!-- jQuery is distributed with Sphinx already -->
  <!-- <script src="../_static/jquery.min.js"></script> -->
  <script src="../_static/js/bootstrap.min.js"></script>

  </head><body>
<div class="container">
  <nav class="navbar navbar-expand-md navbar-light bg-light">
    <a class="navbar-brand align-text-middle" href="../index.html">
      <img src="../_static/fatf.png"
       alt="Logo"
       width="35" height="35"
       class="d-inline-block align-middle">
      FAT-Forensics
    </a>

    <button class="navbar-toggler"
            type="button"
            data-toggle="collapse"
            data-target="#navbarCollapsedContent">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse"
         id="navbarCollapsedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="../index.html">Home</a>
        </li>

        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" role="button" data-toggle="dropdown">
            Documentation
          </a>
          <div class="dropdown-menu">
            <div class="dropdown-header">FAT-Forensics</div>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../getting_started/index.html">Getting Started</a>
            <a class="dropdown-item" href="../tutorials/index.html">Tutorials</a>
            <a class="dropdown-item" href="../sphinx_gallery_auto/index.html">Examples</a>
            <a class="dropdown-item" href="../api.html">API Reference</a>
            <a class="dropdown-item" href="../how_to/index.html">How-To Guides</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../news.html">News</a>
            <a class="dropdown-item" href="../development.html">Developers Guide</a>
            <a class="dropdown-item" href="../contributors.html">Contributors</a>
            <a class="dropdown-item" href="../changelog.html">Changelog</a>
            <a class="dropdown-item" href="../roadmap.html">Roadmap</a>
          </div>
        </li>

        <li class="nav-item">
          <a class="nav-link" href="../user_guide/index.html">
            FAT User Guide
          </a>
        </li>
      </ul>

      <div class="search_form form-inline">
          <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div>
  </nav>
</div>

<!-- GitHub "fork me" ribbon -->
<!--
<a href="https://github.com/fat-forensics/fat-forensics">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>
-->
<span id="forkongithub">
  <a href="https://github.com/fat-forensics/fat-forensics">
    Fork me on GitHub
  </a>
</span>
<div class="container">
  <div class="row">
    <div class="col-sm-2">
      <div class="container sidebar">
        <!--
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/fatf.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.TabularBlimeyLime</a><ul>
<li><a class="reference internal" href="#examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeylime">Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.html"
                        title="previous chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.SurrogateTabularExplainer</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.html"
                        title="next chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.TabularBlimeyTree</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/generated/fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>-->
        <!-- Add a link to the 'up' page -->
        <div class="row rel">
          <div class="col rellink pad-b-1">
            <a class="btn btn-primary btn-sm"
               href="../api.html"
               role="button">
              Up
              <br/>
              <span class="smallrellink">
                API Reference (0.0.2)
              </span>
              <span class="hiddenrellink left-button">
                API Reference (0.0.2)
              </span>
              
            </a>
          </div>
        </div>

        <!-- Add a links to the 'relative' pages -->

        <div class="row rel">
          <div class="col-6 rellink
                      pad-r-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.html"
               accesskey="P"
               role="button">
              Previous
              <br/>
              <span class="smallrellink">
                fatf.transpar...
              </span>
                  <span class="hiddenrellink
                               left-button
                               "
                        data-container="body">
                  fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer
                  </span>
            </a>
          </div>
          <div class="col-6 rellink
                      pad-l-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.html"
               accesskey="N"
               role="button">
              Next
              <br/>
              <span class="smallrellink">
                fatf.transpar...
              </span>
                  <span class="hiddenrellink
                               right-button
                               "
                        data-container="body">
                  fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree
                  </span>
            </a>
          </div>
        </div>

        

        <!-- Add a citation banner -->
        <div class="alert alert-info" role="alert" style="font-size: 89%; margin-top: 16px;">
          Please <a href="../getting_started/cite.html"><b>cite us</b></a> if you use the software.
        </div>

        <!-- Add a page map -->

        <div class="row toc">
          <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.TabularBlimeyLime</a><ul>
<li><a class="reference internal" href="#examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeylime">Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime</span></code></a></li>
</ul>
</li>
</ul>

        </div>

      </div>
    </div>
    

    <div class="col col-sm-10">
      <div class="container">
        <div class="row">
        
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="fatf-transparency-predictions-surrogate-explainers-tabularblimeylime">
<h1><a class="reference internal" href="../api.html#module-fatf.transparency.predictions.surrogate_explainers" title="fatf.transparency.predictions.surrogate_explainers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code></a>.TabularBlimeyLime<a class="headerlink" href="#fatf-transparency-predictions-surrogate-explainers-tabularblimeylime" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime">
<em class="property">class </em><code class="descclassname">fatf.transparency.predictions.surrogate_explainers.</code><code class="descname">TabularBlimeyLime</code><span class="sig-paren">(</span><em>dataset: numpy.ndarray</em>, <em>predictive_model: object</em>, <em>categorical_indices: Optional[List[Union[str</em>, <em>int]]] = None</em>, <em>class_names: Optional[List[str]] = None</em>, <em>feature_names: Optional[List[str]] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/fat-forensics/fat-forensics/blob/f76a9a6/fatf/transparency/predictions/surrogate_explainers.py#L726"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime" title="Permalink to this definition">¶</a></dt>
<dd><p>A tabular LIME explainer – a surrogate explainer based on a linear model.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.0.2.</span></p>
</div>
<p>This class implements Local Interpretable Model-agnostic Explanations
(<a class="reference external" href="https://github.com/marcotcr/lime">LIME</a>) introduced by <a class="reference internal" href="#r3b5bab701858-ribeiro2016why" id="id1">[RIBEIRO2016WHY]</a>. This implementation mirrors the
one in the <a class="reference external" href="https://github.com/marcotcr/lime">official LIME package</a>, which is available under the
<code class="docutils literal notranslate"><span class="pre">lime.lime_tabular.LimeTabularExplainer</span></code> class therein.</p>
<p>This explainer uses a quartile discretiser
(<a class="reference internal" href="fatf.utils.data.discretisation.QuartileDiscretiser.html#fatf.utils.data.discretisation.QuartileDiscretiser" title="fatf.utils.data.discretisation.QuartileDiscretiser"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.discretisation.QuartileDiscretiser</span></code></a>) and a normal
sampler (<a class="reference internal" href="fatf.utils.data.augmentation.NormalSampling.html#fatf.utils.data.augmentation.NormalSampling" title="fatf.utils.data.augmentation.NormalSampling"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.augmentation.NormalSampling</span></code></a>) for
augmenting the data. The following steps are taken to generate the
explanation (when the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method is called):</p>
<ul class="simple">
<li><p>The input <code class="docutils literal notranslate"><span class="pre">data_row</span></code> is discretised using the quartile discretiser.
The numerical features are binned and the categorical ones are left
unchanged (selected via the <code class="docutils literal notranslate"><span class="pre">categorical_indices</span></code> parameter).</p></li>
<li><p>The data are sampled around the discretised <code class="docutils literal notranslate"><span class="pre">data_row</span></code> using the normal
sampler. Since after the discretisation all of the features are
categorical the bin indices are sampled based on their frequency
in (the discretised version of) the <code class="docutils literal notranslate"><span class="pre">dataset</span></code> used to initialise this
class.</p></li>
<li><p>The sampled data are reverted back to their original domain and predicted
with the black-box model (<code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> used to initialise this
class). This step is done via sampling each (numerical) feature value
from the corresponding bin using the truncated normal distribution for
which minimum (lower threshold), maximum (upper threshold), mean and
standard deviation are computed empirically from all the data points from
the <code class="docutils literal notranslate"><span class="pre">dataset</span></code> for which feature values fall into that bin. The
categorical features are left unchanged.</p></li>
<li><p>The discretised sampled data set is binarised by comparing each row with
the user-specified <code class="docutils literal notranslate"><span class="pre">data_row</span></code> (in the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method).
This step is performed by taking XNOR logical operation between the two
– 1 if the feature value is the same in a row of the discretised data
set and the <code class="docutils literal notranslate"><span class="pre">data_row</span></code> and 0 if it is different.</p></li>
<li><p>The Euclidean distance between the binarised sampled data and binarised
<code class="docutils literal notranslate"><span class="pre">data_row</span></code> is computed and passed through an exponential kernel
(<a class="reference internal" href="fatf.utils.kernels.exponential_kernel.html#fatf.utils.kernels.exponential_kernel" title="fatf.utils.kernels.exponential_kernel"><code class="xref py py-func docutils literal notranslate"><span class="pre">fatf.utils.kernels.exponential_kernel</span></code></a>) to get similarity scores,
which will be used as data point weights when reducing the number of
features with k-LASSO (see below) and training the linear regression.</p></li>
<li><p>K-LASSO is used to limit the number of features in the explanation if
enabled by the user. (This is controlled by the <code class="docutils literal notranslate"><span class="pre">features_number</span></code>
parameter in the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method and by default –
<code class="docutils literal notranslate"><span class="pre">features_number=None</span></code> – the feature selection is not performed.)</p></li>
<li><p>A local (weighted) ridge regression (<code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.Ridge</span></code>) is
fitted to the sampled and binarised data with the target being a
vector of probabilities outputted by the black-box model for the selected
class (one-vs-rest). By default, one model is trained for all of the
classes (<code class="docutils literal notranslate"><span class="pre">explained_class=None</span></code> in the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method),
however the class to be explained can be specified by the user.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>How to interpret the results?</p>
<p>Because the local surrogate model is trained on the binarised sampled
data that is parsed through the XNOR operation, the parameters extracted
from this model (feature importances) should be interpreted as an answer
to the following question:</p>
<blockquote>
<div><p>“Had this particular feature value of the explained data point
been outside of this range (for numerical features) or had a
different value (for categorical feature), how would that influence
the probability of this point belonging to the explained class?”</p>
</div></blockquote>
</div>
<p>This LIME implementation is limited to black-box <strong>probabilistic</strong> models
(similarly to the <a class="reference external" href="https://github.com/marcotcr/lime/blob/master/lime/lime_tabular.py#L357">official implementation</a>), i.e., the
<code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> must have a <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method.
In all cases the local model will be trained using the <strong>one-vs-rest</strong>
approach since the output of the global model is an array with
probabilities of each class (the classes to be explained can be selected
using the <code class="docutils literal notranslate"><span class="pre">explained_class</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code>
method).
The column indices indicated as categorical features (via the
<code class="docutils literal notranslate"><span class="pre">categorical_indices</span></code> parameter) will not be discretised.</p>
<p>For detailed instructions on how to build a custom surrogate explainer
(to avoid tinkering with this class) please see the
<a class="reference internal" href="../how_to/transparency/tabular-surrogates.html#how-to-tabular-surrogates"><span class="std std-ref">How to build LIME yourself (bLIMEy) – Surrogate Tabular Explainers</span></a> <em>how-to guide</em>.</p>
<p>For additional parameters, warnings and errors description please see the
documentation of the parent class <a class="reference internal" href="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.html#fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer" title="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer</span></code></a>.</p>
<dl class="citation">
<dt class="label" id="r3b5bab701858-ribeiro2016why"><span class="brackets"><a class="fn-backref" href="#id1">RIBEIRO2016WHY</a></span></dt>
<dd><p>Ribeiro, M.T., Singh, S. and Guestrin, C., 2016,
August. Why should i trust you?: Explaining the predictions of any
classifier. In Proceedings of the 22nd ACM SIGKDD international
conference on knowledge discovery and data mining (pp. 1135-1144). ACM.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dataset</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A 2-dimensional numpy array with a dataset (utilised in various ways
throughout the explainer).</p>
</dd>
<dt><strong>predictive_model</strong><span class="classifier">object</span></dt><dd><p>A pre-trained (black-box) predictive model to be explained. If
<code class="docutils literal notranslate"><span class="pre">as_probabilistic</span></code> (see below) is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, it must have a
<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method that takes a data set as the only required
input parameter and returns a 2-dimensional numpy array with
probabilities of belonging to each class. Otherwise, if
<code class="docutils literal notranslate"><span class="pre">as_probabilistic</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> must
have a <code class="docutils literal notranslate"><span class="pre">predict</span></code> method that outputs a 1-dimensional array with
(class) predictions.</p>
</dd>
<dt><strong>categorical_indices</strong><span class="classifier">List[column indices], optional (default=None)</span></dt><dd><p>A list of column indices in the input <code class="docutils literal notranslate"><span class="pre">dataset</span></code> that should be
treated as categorical features.</p>
</dd>
<dt><strong>class_names</strong><span class="classifier">List[string], optional (default=None)</span></dt><dd><p>A list of strings defining the names of classes. If the predictive
model is probabilistic, the order of the class names should correspond
to the order of columns outputted by the model. For other models the
order should correspond to lexicographical ordering of all the possible
outputs of this model. For example, if the model outputs
<code class="docutils literal notranslate"><span class="pre">['a',</span> <span class="pre">'c',</span> <span class="pre">'0']</span></code> the class names should be given for
<code class="docutils literal notranslate"><span class="pre">['0',</span> <span class="pre">'a',</span> <span class="pre">'c']</span></code> ordering.</p>
</dd>
<dt><strong>feature_names</strong><span class="classifier">List[string], optional (default=None)</span></dt><dd><p>A list of strings defining the names of the <code class="docutils literal notranslate"><span class="pre">dataset</span></code> features. The
order of the names should correspond to the order of features in the
<code class="docutils literal notranslate"><span class="pre">dataset</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>discretiser</strong><span class="classifier">fatf.utils.data.discretisation.Discretiser</span></dt><dd><p>An instance of the quartile discretiser
(<a class="reference internal" href="fatf.utils.data.discretisation.QuartileDiscretiser.html#fatf.utils.data.discretisation.QuartileDiscretiser" title="fatf.utils.data.discretisation.QuartileDiscretiser"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.discretisation.QuartileDiscretiser</span></code></a>)
initialised with the input <code class="docutils literal notranslate"><span class="pre">dataset</span></code> and used to discretise
the <code class="docutils literal notranslate"><span class="pre">data_row</span></code> when the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method is called.</p>
</dd>
<dt><strong>augmenter</strong><span class="classifier">fatf.utils.data.augmentation.Augmentation</span></dt><dd><p>An instance of the normal sampling augmenter
(<a class="reference internal" href="fatf.utils.data.augmentation.NormalSampling.html#fatf.utils.data.augmentation.NormalSampling" title="fatf.utils.data.augmentation.NormalSampling"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.augmentation.NormalSampling</span></code></a>)
used to sample new data points around the discretised <code class="docutils literal notranslate"><span class="pre">data_row</span></code>
(in the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method).</p>
</dd>
<dt><strong>bin_sampling_values</strong><span class="classifier">Dictionary[dataset column index, Dictionary[discretised bin id, Tuple(float, float, float, float)]]</span></dt><dd><p>A dictionary holding characteristics for each bin of each numerical
feature. The characteristic are represented as a 4-tuple consisting of:
the lower bin boundary, the upper bin boundary, the empirical mean of
of all the values of this feature for data points (in <code class="docutils literal notranslate"><span class="pre">dataset</span></code>)
falling into that bin, and the empirical standard deviation (calculated
in the same way). For the edge bins, if there are data available the
lower edge is calculated empirically (as the minimum of the
corresponding feature values falling into that bin), otherwise it is
set to <code class="docutils literal notranslate"><span class="pre">-numpy.inf</span></code>. The same applies to the upper edge, which is
either set to <code class="docutils literal notranslate"><span class="pre">numpy.inf</span></code> or calculated empirically (as the maximum
of the corresponding feature values falling into that bin).
If there are no data points to calculate the mean and standard
deviation for a given bin, these two values are set to <code class="docutils literal notranslate"><span class="pre">numpy.nan</span></code>.
(This does not influence the future reverse sampling, for which this
attribute is used: since there were no data for a given bin, the
frequency of data for that bin is 0, therefore no data falling into
this bin will be sampled.)</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>ImportError</strong></dt><dd><p>The scikit-learn package is missing.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-center">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.explain_instance" title="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.explain_instance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explain_instance</span></code></a>(data_row, numpy.void], …)</p></td>
<td><p>Explains the <code class="docutils literal notranslate"><span class="pre">data_row</span></code> with linear regression feature importance.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.explain_instance">
<code class="descname">explain_instance</code><span class="sig-paren">(</span><em>data_row: Union[numpy.ndarray, numpy.void], explained_class: Union[int, str, None] = None, samples_number: int = 50, features_number: Optional[int] = None, kernel_width: Optional[float] = None, return_models: bool = False</em><span class="sig-paren">)</span> &#x2192; Union[Dict[str, Dict[str, float]], Tuple[Dict[str, Dict[str, float]], Dict[str, fatf.utils.models.models.Model]]]<a class="reference external" href="https://github.com/fat-forensics/fat-forensics/blob/f76a9a6/fatf/transparency/predictions/surrogate_explainers.py#L1136"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.explain_instance" title="Permalink to this definition">¶</a></dt>
<dd><p>Explains the <code class="docutils literal notranslate"><span class="pre">data_row</span></code> with linear regression feature importance.</p>
<p>By default the explanations will be produced for all of the classes,
what can be limited by selecting a specific class with the
<code class="docutils literal notranslate"><span class="pre">explained_class</span></code> parameter. The default <code class="docutils literal notranslate"><span class="pre">kernel_width</span></code> is computed
as the square root of the number of features multiplied by 0.75.
Also, by default, all of the (interpretable) features will be used
to create an explanation, what can be limited by setting the
<code class="docutils literal notranslate"><span class="pre">features_number</span></code> parameter. The data sampling around the
<code class="docutils literal notranslate"><span class="pre">data_row</span></code> can be customised by specifying the number of points to be
generated (<code class="docutils literal notranslate"><span class="pre">samples_number</span></code>).</p>
<p>By default, this method only returns feature importance, however
by setting <code class="docutils literal notranslate"><span class="pre">return_models</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will also return the local
linear surrogates for further analysis and processing done outside of
this method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The exact description of the explanation generation procedure can
be found in the documentation of this class (<a class="reference internal" href="#fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime" title="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime</span></code></a>).</p>
</div>
<p>For additional parameters, warnings and errors please see the parent
class method <a class="reference internal" href="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.html#fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.explain_instance" title="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.explain_instance"><code class="xref py py-func docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.explain_instance</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>data_row</strong><span class="classifier">Union[numpy.ndarray, numpy.void]</span></dt><dd><p>A data point to be explained (1-dimensional numpy array).</p>
</dd>
<dt><strong>explained_class</strong><span class="classifier">Union[integer, string], optional (default=None)</span></dt><dd><p>The class to be explained. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, all of the classes will be
explained. This can either be the index of the class (the column
index of the probabilistic vector) or the class name (taken from
<code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>).</p>
</dd>
<dt><strong>samples_number</strong><span class="classifier">integer, optional (default=50)</span></dt><dd><p>The number of data points sampled from the normal augmenter, which
will be used to fit the local surrogate model.</p>
</dd>
<dt><strong>features_number</strong><span class="classifier">integer, optional (default=None)</span></dt><dd><p>The maximum number of (interpretable) features – found with
K-LASSO – to be used in the explanation (the local surrogate
model is trained with this feature subset). By default (<code class="docutils literal notranslate"><span class="pre">None</span></code>),
all of the (interpretable) features will be used.</p>
</dd>
<dt><strong>kernel_width</strong><span class="classifier">float, optional (default=None)</span></dt><dd><p>The width of the exponential kernel used when computing weights of
the sampled data based on the distances between the sampled data
and the <code class="docutils literal notranslate"><span class="pre">data_row</span></code>.The default <code class="docutils literal notranslate"><span class="pre">kernel_width</span></code>
(<code class="docutils literal notranslate"><span class="pre">kernel_width=None</span></code>) is computed as the square root of the
number of features multiplied by 0.75.</p>
</dd>
<dt><strong>return_models</strong><span class="classifier">boolean, optional (default=False)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, this method will return both the feature importance
explanation dictionary and a dictionary holding the local models.
Otherwise, only the first dictionary will be returned.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>explanations</strong><span class="classifier">Dictionary[string, Dictionary[string, float]]</span></dt><dd><p>A dictionary holding dictionaries that contain feature
importance – where the feature names are taken from
<code class="docutils literal notranslate"><span class="pre">self.feature_names</span></code> and the feature importances are extracted
from local linear surrogates. These dictionaries are held under
keys corresponding to class names (taken from
<code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>).</p>
</dd>
<dt><strong>models</strong><span class="classifier">sklearn.linear_model.base.LinearModel, optional</span></dt><dd><p>A dictionary holding locally fitted surrogate linear models
held under class name keys (taken from <code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>).
This dictionary is only returned when the <code class="docutils literal notranslate"><span class="pre">return_models</span></code>
parameter is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>TypeError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">explained_class</span></code> parameter is neither <code class="docutils literal notranslate"><span class="pre">None</span></code>, an integer
or a string. The <code class="docutils literal notranslate"><span class="pre">samples_number</span></code> parameter is not an integer.
The <code class="docutils literal notranslate"><span class="pre">features_number</span></code> parameter is neither <code class="docutils literal notranslate"><span class="pre">None</span></code> nor an
integer. The <code class="docutils literal notranslate"><span class="pre">kernel_width</span></code> parameter is neither <code class="docutils literal notranslate"><span class="pre">None</span></code> nor
a number. The <code class="docutils literal notranslate"><span class="pre">return_models</span></code> parameter is not a boolean.</p>
</dd>
<dt><strong>ValueError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">samples_number</span></code> parameter is a non-positive integer (smaller
than 1). The <code class="docutils literal notranslate"><span class="pre">features_number</span></code> parameter is a non-positive
integer (smaller than 1). The <code class="docutils literal notranslate"><span class="pre">kernel_width</span></code> parameter is a
non-positive number (smaller or equal to 0).
The <code class="docutils literal notranslate"><span class="pre">explained_class</span></code> specified by the user could neither be
recognised as one of the allowed class names (<code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>)
nor an index of a class name.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeylime">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime</span></code><a class="headerlink" href="#examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeylime" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the LIME tabular explainer to explain a prediction."><div class="figure align-center" id="id2">
<img alt="../_images/sphx_glr_xmpl_transparency_lime_thumb.png" src="../_images/sphx_glr_xmpl_transparency_lime_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../sphinx_gallery_auto/transparency/xmpl_transparency_lime.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-lime-py"><span class="std std-ref">Using LIME Explainer</span></a></span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
</div><div class="clear:both"></div></div>
</div>


          </div>
        </div>
      </div>
        </div>
      </div>
    </div>
  </div>
</div>

  <div class="container cusotm-footer">
    <div class="row">
      <div class="col-3">
        &copy; 2018--2019, Kacper Sokol et al.
      </div>
      <div class="col-6">
        <a class="footer-img-link" href="contributors.html#funding">
          <img src="../_static/img/bristol.svg" title="Univeristy of Bristol" style="max-height: 30px">
          &nbsp;
          <img src="../_static/img/thales.svg" title="Thales" style="max-height: 20px">
        </a>
        <br>
        <a href="contributors.html#funding" style="top: 4px; position: relative;">
          More information on our contributors
        </a>
      </div>
      <div class="col-3">
        <a href="../_sources/generated/fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.rst.txt" rel="nofollow">
          Show this page source
        </a>
      </div>
    </div>
  </div>

  
  <script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-142154492-1', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  
  <script>
    (function() {
      var cx = '014039732624725851926:mpducezglrq';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
  
  </body>
</html>