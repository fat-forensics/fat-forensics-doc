

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
  
    <title>fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree &#8212; FAT Forensics 0.1.0 documentation</title>
  <!-- html title is before nature.css - we use this hack to load bootstrap first -->
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css">

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="canonical" href="https://fat-forensics.org/generated/fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.html" />
    <link rel="shortcut icon" href="../_static/fatf.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="fatf.transparency.sklearn.tools.SKLearnExplainer" href="fatf.transparency.sklearn.tools.SKLearnExplainer.html" />
    <link rel="prev" title="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime" href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.html" />
  <!-- jQuery first, then Bootstrap JS -->
  <!-- jQuery is distributed with Sphinx already -->
  <!-- <script src="../_static/jquery.min.js"></script> -->
  <script src="../_static/js/bootstrap.min.js"></script>

  </head><body>
<div class="container">
  <nav class="navbar navbar-expand-md navbar-light bg-light">
    <a class="navbar-brand align-text-middle" href="../index.html">
      <img src="../_static/fatf.png"
       alt="Logo"
       width="35" height="35"
       class="d-inline-block align-middle">
      FAT Forensics
    </a>

    <button class="navbar-toggler"
            type="button"
            data-toggle="collapse"
            data-target="#navbarCollapsedContent">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse"
         id="navbarCollapsedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="../index.html">Home</a>
        </li>

        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" role="button" data-toggle="dropdown">
            Documentation
          </a>
          <div class="dropdown-menu">
            <div class="dropdown-header">FAT Forensics</div>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../getting_started/index.html">Getting Started</a>
            <a class="dropdown-item" href="../tutorials/index.html">Tutorials</a>
            <a class="dropdown-item" href="../sphinx_gallery_auto/index.html">Examples</a>
            <a class="dropdown-item" href="../api.html">API Reference</a>
            <a class="dropdown-item" href="../how_to/index.html">How-To Guides</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../news.html">News</a>
            <a class="dropdown-item" href="../development.html">Developers Guide</a>
            <a class="dropdown-item" href="../contributors.html">Contributors</a>
            <a class="dropdown-item" href="../changelog.html">Changelog</a>
            <a class="dropdown-item" href="../roadmap.html">Roadmap</a>
          </div>
        </li>

        <li class="nav-item">
          <a class="nav-link" href="../user_guide/index.html">
            FAT User Guide
          </a>
        </li>
      </ul>

      <div class="search_form form-inline">
          <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div>
  </nav>
</div>

<!-- GitHub "fork me" ribbon -->
<!--
<a href="https://github.com/fat-forensics/fat-forensics">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>
-->
<span id="forkongithub">
  <a href="https://github.com/fat-forensics/fat-forensics">
    Fork me on GitHub
  </a>
</span>
<div class="container">
  <div class="row">
    <div class="col-sm-2">
      <div class="container sidebar">
        <!--
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/fatf.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.TabularBlimeyTree</a><ul>
<li><a class="reference internal" href="#examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeytree">Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.html"
                        title="previous chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.TabularBlimeyLime</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="fatf.transparency.sklearn.tools.SKLearnExplainer.html"
                        title="next chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.sklearn.tools</span></code>.SKLearnExplainer</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/generated/fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>-->
        <!-- Add a link to the 'up' page -->
        <div class="row rel">
          <div class="col rellink pad-b-1">
            <a class="btn btn-primary btn-sm"
               href="../api.html"
               role="button">
              Up
              <br/>
              <span class="smallrellink">
                API Reference (0.1.0)
              </span>
              <span class="hiddenrellink left-button">
                API Reference (0.1.0)
              </span>
              
            </a>
          </div>
        </div>

        <!-- Add a links to the 'relative' pages -->

        <div class="row rel">
          <div class="col-6 rellink
                      pad-r-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime.html"
               accesskey="P"
               role="button">
              Previous
              <br/>
              <span class="smallrellink">
                fatf.transpar...
              </span>
                  <span class="hiddenrellink
                               left-button
                               "
                        data-container="body">
                  fatf.transparency.predictions.surrogate_explainers.TabularBlimeyLime
                  </span>
            </a>
          </div>
          <div class="col-6 rellink
                      pad-l-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="fatf.transparency.sklearn.tools.SKLearnExplainer.html"
               accesskey="N"
               role="button">
              Next
              <br/>
              <span class="smallrellink">
                fatf.transpar...
              </span>
                  <span class="hiddenrellink
                               right-button
                               "
                        data-container="body">
                  fatf.transparency.sklearn.tools.SKLearnExplainer
                  </span>
            </a>
          </div>
        </div>

        

        <!-- Add a citation banner -->
        <div class="alert alert-info" role="alert" style="font-size: 89%; margin-top: 16px;">
          Please <a href="../getting_started/cite.html"><b>cite us</b></a> if you use the software.
        </div>

        <!-- Add a page map -->

        <div class="row toc">
          <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.TabularBlimeyTree</a><ul>
<li><a class="reference internal" href="#examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeytree">Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree</span></code></a></li>
</ul>
</li>
</ul>

        </div>

      </div>
    </div>
    

    <div class="col col-sm-10">
      <div class="container">
        <div class="row">
        
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="fatf-transparency-predictions-surrogate-explainers-tabularblimeytree">
<h1><a class="reference internal" href="../api.html#module-fatf.transparency.predictions.surrogate_explainers" title="fatf.transparency.predictions.surrogate_explainers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code></a>.TabularBlimeyTree<a class="headerlink" href="#fatf-transparency-predictions-surrogate-explainers-tabularblimeytree" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree">
<em class="property">class </em><code class="descclassname">fatf.transparency.predictions.surrogate_explainers.</code><code class="descname">TabularBlimeyTree</code><span class="sig-paren">(</span><em>dataset: numpy.ndarray</em>, <em>predictive_model: object</em>, <em>as_probabilistic: bool = True</em>, <em>as_regressor: bool = False</em>, <em>categorical_indices: Optional[List[Union[str</em>, <em>int]]] = None</em>, <em>class_names: Optional[List[str]] = None</em>, <em>classes_number: Optional[int] = None</em>, <em>feature_names: Optional[List[str]] = None</em>, <em>unique_predictions: Optional[List[Union[str</em>, <em>int]]] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/fat-forensics/fat-forensics/blob/6fa252a/fatf/transparency/predictions/surrogate_explainers.py#L1506"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree" title="Permalink to this definition">¶</a></dt>
<dd><p>A surrogate explainer based on a decision tree.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.1.0: </span>Added support for regression models.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.0.2.</span></p>
</div>
<p>This explainer does not use an interpretable data representation (as one
is learnt by the tree). The data augmentation is done with <em>Mixup</em>
(<a class="reference internal" href="fatf.utils.data.augmentation.Mixup.html#fatf.utils.data.augmentation.Mixup" title="fatf.utils.data.augmentation.Mixup"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.augmentation.Mixup</span></code></a>) around the data point
specified in the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method. No data weighting procedure
is used when fitting the local surrogate model.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">as_regressor</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, a surrogate regression tree is
fitted to a black-box regression. When it is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
<code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> is treated as a classifier. When the underlying
predictive model is probabilistic (<code class="docutils literal notranslate"><span class="pre">as_probabilistic=True</span></code>), the local
decision tree is trained as a regressor of probabilities output by the
black-box <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code>. When the <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> is a
non-probabilistic classifier, the local decision tree is a classifier that
is either fitted as one-vs-rest for a selected class or mimics the
classification problem by fitting a multi-class classifier.</p>
<p>The explanation output by the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method is a simple
feature importance measure extracted from the local tree. Alternatively,
the local tree model can be returned for further processing or visualising.</p>
<p>Since this explainer is based on scikit-learn’s implementation of decision
trees, it does not support structured arrays and categorical (text-based)
features.</p>
<p>For additional parameters, warnings and errors please see the documentation
of the parent class: <a class="reference internal" href="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.html#fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer" title="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>augmenter</strong><span class="classifier">fatf.utils.data.augmentation.Augmentation</span></dt><dd><p>The augmenter class (<a class="reference internal" href="fatf.utils.data.augmentation.Mixup.html#fatf.utils.data.augmentation.Mixup" title="fatf.utils.data.augmentation.Mixup"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.augmentation.Mixup</span></code></a>) used
for local data sampling.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>ImportError</strong></dt><dd><p>The scikit-learn package is missing.</p>
</dd>
<dt><strong>TypeError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">dataset</span></code> parameter is a structured array or the <code class="docutils literal notranslate"><span class="pre">dataset</span></code>
contains non-numerical features.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-center">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.explain_instance" title="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.explain_instance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explain_instance</span></code></a>(data_row, numpy.void], …)</p></td>
<td><p>Explains the <code class="docutils literal notranslate"><span class="pre">data_row</span></code> with decision tree feature importance.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.explain_instance">
<code class="descname">explain_instance</code><span class="sig-paren">(</span><em>data_row: Union[numpy.ndarray, numpy.void], explained_class: Union[int, str, None] = None, one_vs_rest: bool = True, samples_number: int = 50, maximum_depth: int = 3, return_models: bool = False</em><span class="sig-paren">)</span> &#x2192; Union[Dict[str, Dict[str, float]], Tuple[Dict[str, Dict[str, float]], Union[Dict[str, fatf.utils.models.models.Model], fatf.utils.models.models.Model]]]<a class="reference external" href="https://github.com/fat-forensics/fat-forensics/blob/6fa252a/fatf/transparency/predictions/surrogate_explainers.py#L1782"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.explain_instance" title="Permalink to this definition">¶</a></dt>
<dd><p>Explains the <code class="docutils literal notranslate"><span class="pre">data_row</span></code> with decision tree feature importance.</p>
<p>If the black-box model is a classifier, the explanations will be
produced for all of the classes by default. This behaviour can be
changed by selecting a specific class with the <code class="docutils literal notranslate"><span class="pre">explained_class</span></code>
parameter. For black-box classifiers, the local tree is learnt as
a one-vs-rest (for one class at a time or only for the selected class)
model by default. This is a requirement for probabilistic black-box
models as the local model has to be a regression (tree) of
probabilities for a selected class. However, when the black-box model
is a non-probabilistic classifier, the local tree can either be learnt
as one-vs-rest or multi-class (chosen by setting the <code class="docutils literal notranslate"><span class="pre">one_vs_rest</span></code>
parameter). The depth of the local tree can also be limited to improve
its comprehensiveness by setting the <code class="docutils literal notranslate"><span class="pre">maximum_depth</span></code> parameter.</p>
<p>The data sampling around the <code class="docutils literal notranslate"><span class="pre">data_row</span></code> can be customised by
specifying the number of points to be generated (<code class="docutils literal notranslate"><span class="pre">samples_number</span></code>).
By default, this method only returns feature importance, however
by setting <code class="docutils literal notranslate"><span class="pre">return_models</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will also return the local
tree surrogates for further analysis and processing done outside of
this method.</p>
<p>For additional parameters, warnings and errors please see the parent
class method <a class="reference internal" href="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.html#fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.explain_instance" title="fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.explain_instance"><code class="xref py py-func docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.SurrogateTabularExplainer.explain_instance</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>data_row</strong><span class="classifier">Union[numpy.ndarray, numpy.void]</span></dt><dd><p>A data point to be explained (1-dimensional numpy array).</p>
</dd>
<dt><strong>explained_class</strong><span class="classifier">Union[integer, string], optional (default=None)</span></dt><dd><p>The class to be explained. This parameter is ignored when the
black-box model is a regressor. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, all of the classes
will be explained. For probabilistic (black-box) models this can
either be the index of the class (the column index of the
probabilistic vector) or the class name (taken from
<code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>). For non-probabilistic (black-box) models
this can either be the name of the class (taken from
<code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>), the prediction value (taken from
<code class="docutils literal notranslate"><span class="pre">self.unique_predictions</span></code>) or the index of any of these two
(assuming the lexicographical ordering of the unique predictions
output by the model).</p>
</dd>
<dt><strong>one_vs_rest</strong><span class="classifier">boolean, optional (default=True)</span></dt><dd><p>A boolean indicating whether the local model should be fitted as
one-vs-rest (required for probabilistic models) or as a multi-class
classifier. This parameter is ignored when the black-box model is
a regressor.</p>
</dd>
<dt><strong>samples_number</strong><span class="classifier">integer, optional (default=50)</span></dt><dd><p>The number of data points sampled from the Mixup augmenter, which
will be used to fit the local surrogate model.</p>
</dd>
<dt><strong>maximum_depth</strong><span class="classifier">integer, optional (default=3)</span></dt><dd><p>The maximum depth of the local decision tree surrogate model. The
lower the number the smaller the decision tree, therefore making it
(and the resulting explanations) more comprehensible.</p>
</dd>
<dt><strong>return_models</strong><span class="classifier">boolean, optional (default=False)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, this method will return both the feature importance
explanation dictionary and a dictionary holding the local models.
Otherwise, only the first dictionary will be returned.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>explanations</strong><span class="classifier">Dictionary[string, Dictionary[string, float]]</span></dt><dd><p>A dictionary holding dictionaries that contain feature
importance – where the feature names are taken from
<code class="docutils literal notranslate"><span class="pre">self.feature_names</span></code> and the feature importances are extracted
from local surrogate trees. These dictionaries are held under keys
corresponding to class names (taken from <code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>).</p>
</dd>
<dt><strong>models</strong><span class="classifier">sklearn.tree.tree.BaseDecisionTree, optional</span></dt><dd><p>A dictionary holding locally fitted surrogate decision tree models
held under class name keys (taken from <code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>).
This dictionary is only returned when the <code class="docutils literal notranslate"><span class="pre">return_models</span></code>
parameter is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>RuntimeError</strong></dt><dd><p>A surrogate cannot be fitted as the (black-box) predictions for
the sampled data are of a single class or do not have the requested
class in case of the one-vs-rest local model (only applies to
black-box models that are non-probabilistic classifiers
(<code class="docutils literal notranslate"><span class="pre">self.as_probabilistic=False</span></code> and <code class="docutils literal notranslate"><span class="pre">self.as_regressor=False</span></code>).</p>
</dd>
<dt><strong>TypeError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">explained_class</span></code> parameter is neither <code class="docutils literal notranslate"><span class="pre">None</span></code>, a string or
an integer. The <code class="docutils literal notranslate"><span class="pre">one_vs_rest</span></code> parameter is not a boolean.
The <code class="docutils literal notranslate"><span class="pre">samples_number</span></code> parameter is not an integer.
The <code class="docutils literal notranslate"><span class="pre">maximum_depth</span></code> parameter is not an integer.
The <code class="docutils literal notranslate"><span class="pre">return_models</span></code> parameter is not a boolean.</p>
</dd>
<dt><strong>ValueError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">samples_number</span></code> parameter is not a positive integer (larger
than 0). The <code class="docutils literal notranslate"><span class="pre">maximum_depth</span></code> parameter is not a positive integer
(larger than 0).
The <code class="docutils literal notranslate"><span class="pre">explained_class</span></code> parameter is not recognised. For
probabilistic (black-box) models this means that it could neither
be recognised as a class name (<code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>) nor an index
of a class name. For non-probabilistic (black-box) models this
means that it could neither be recognised as on of the possible
predictions (<code class="docutils literal notranslate"><span class="pre">self.unique_predictions</span></code>) or a class name
(<code class="docutils literal notranslate"><span class="pre">self.class_names</span></code>) nor as an index of either of these two.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Warns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>UserWarning</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">one_vs_rest</span></code> parameter was set to <code class="docutils literal notranslate"><span class="pre">True</span></code> for an
explainer that is based on a probabilistic (black-box) model.
This is not possible, hence the <code class="docutils literal notranslate"><span class="pre">one_vs_rest</span></code> parameter will be
overwritten to <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Choosing a class to be explained (via the <code class="docutils literal notranslate"><span class="pre">explained_class</span></code>
parameter) is not required when requesting a multi-class local
classifier (<code class="docutils literal notranslate"><span class="pre">one_vs_rest=False</span></code>) for a non-probabilistic
black-box model since all of the classes will share a single
surrogate.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeytree">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree</span></code><a class="headerlink" href="#examples-using-fatf-transparency-predictions-surrogate-explainers-tabularblimeytree" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use a tabular surrogate tree-based explainer to explain a predi..."><div class="figure align-center" id="id1">
<img alt="../_images/sphx_glr_xmpl_transparency_tree_thumb.png" src="../_images/sphx_glr_xmpl_transparency_tree_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="../sphinx_gallery_auto/transparency/xmpl_transparency_tree.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-tree-py"><span class="std std-ref">Using a Surrogate Tree Explainer</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div><div class="clear:both"></div></div>
</div>


          </div>
        </div>
      </div>
        </div>
      </div>
    </div>
  </div>
</div>

  <div class="container cusotm-footer">
    <div class="row">
      <div class="col-3">
        &copy; 2018--2020, Kacper Sokol et al.
      </div>
      <div class="col-6">
        <a class="footer-img-link" href="contributors.html#funding">
          <img src="../_static/img/bristol.svg" title="Univeristy of Bristol" style="max-height: 30px">
          &nbsp;
          <img src="../_static/img/thales.svg" title="Thales" style="max-height: 20px">
        </a>
        <br>
        <a href="contributors.html#funding" style="top: 4px; position: relative;">
          More information on our contributors
        </a>
      </div>
      <div class="col-3">
        <a href="../_sources/generated/fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.rst.txt" rel="nofollow">
          Show this page source
        </a>
      </div>
    </div>
  </div>

  
  <script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-142154492-1', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  
  <script>
    (function() {
      var cx = '014039732624725851926:mpducezglrq';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
  
  </body>
</html>