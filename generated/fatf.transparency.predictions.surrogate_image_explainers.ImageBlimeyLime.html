

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  
    <title>fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime &#8212; FAT Forensics 0.1.2 documentation</title>
  <!-- html title is before nature.css - we use this hack to load bootstrap first -->
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css">

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="canonical" href="https://fat-forensics.org/generated/fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.html" />
    <link rel="shortcut icon" href="../_static/fatf.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="fatf.transparency.sklearn.tools.SKLearnExplainer" href="fatf.transparency.sklearn.tools.SKLearnExplainer.html" />
    <link rel="prev" title="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree" href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.html" />
  <!-- jQuery first, then Bootstrap JS -->
  <!-- jQuery is distributed with Sphinx already -->
  <!-- <script src="../_static/jquery.min.js"></script> -->
  <script src="../_static/js/bootstrap.min.js"></script>

  </head><body>
<div class="container">
  <nav class="navbar navbar-expand-md navbar-light bg-light">
    <a class="navbar-brand align-text-middle" href="../index.html">
      <img src="../_static/fatf.png"
       alt="Logo"
       width="35" height="35"
       class="d-inline-block align-middle">
      FAT Forensics
    </a>

    <button class="navbar-toggler"
            type="button"
            data-toggle="collapse"
            data-target="#navbarCollapsedContent">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse"
         id="navbarCollapsedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="../index.html">Home</a>
        </li>

        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" role="button" data-toggle="dropdown">
            Documentation
          </a>
          <div class="dropdown-menu">
            <div class="dropdown-header">FAT Forensics</div>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../getting_started/index.html">Getting Started</a>
            <a class="dropdown-item" href="../tutorials/index.html">Tutorials</a>
            <a class="dropdown-item" href="../sphinx_gallery_auto/index.html">Examples</a>
            <a class="dropdown-item" href="../api.html">API Reference</a>
            <a class="dropdown-item" href="../how_to/index.html">How-To Guides</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../news.html">News</a>
            <a class="dropdown-item" href="../development.html">Developers Guide</a>
            <a class="dropdown-item" href="../contributors.html">Contributors</a>
            <a class="dropdown-item" href="../changelog.html">Changelog</a>
            <a class="dropdown-item" href="../roadmap.html">Roadmap</a>
          </div>
        </li>

        <li class="nav-item">
          <a class="nav-link" href="../user_guide/index.html">
            FAT User Guide
          </a>
        </li>
      </ul>

      <div class="search_form form-inline">
          <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div>
  </nav>
</div>

<!-- GitHub "fork me" ribbon -->
<!--
<a href="https://github.com/fat-forensics/fat-forensics">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>
-->
<span id="forkongithub">
  <a href="https://github.com/fat-forensics/fat-forensics">
    Fork me on GitHub
  </a>
</span>
<div class="container">
  <div class="row">
    <div class="col-sm-2">
      <div class="container sidebar">
        <!--
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/fatf.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_image_explainers</span></code>.ImageBlimeyLime</a><ul>
<li><a class="reference internal" href="#examples-using-fatf-transparency-predictions-surrogate-image-explainers-imageblimeylime">Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime</span></code></a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.html"
                        title="previous chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_explainers</span></code>.TabularBlimeyTree</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="fatf.transparency.sklearn.tools.SKLearnExplainer.html"
                        title="next chapter"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.sklearn.tools</span></code>.SKLearnExplainer</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/generated/fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>-->
        <!-- Add a link to the 'up' page -->
        <div class="row rel">
          <div class="col rellink pad-b-1">
            <a class="btn btn-primary btn-sm"
               href="../api.html"
               role="button">
              Up
              <br/>
              <span class="smallrellink">
                API Reference (0.1.2)
              </span>
              <span class="hiddenrellink left-button">
                API Reference (0.1.2)
              </span>
              
            </a>
          </div>
        </div>

        <!-- Add a links to the 'relative' pages -->

        <div class="row rel">
          <div class="col-6 rellink
                      pad-r-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree.html"
               accesskey="P"
               role="button">
              Previous
              <br/>
              <span class="smallrellink">
                fatf.transpar...
              </span>
                  <span class="hiddenrellink
                               left-button
                               "
                        data-container="body">
                  fatf.transparency.predictions.surrogate_explainers.TabularBlimeyTree
                  </span>
            </a>
          </div>
          <div class="col-6 rellink
                      pad-l-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="fatf.transparency.sklearn.tools.SKLearnExplainer.html"
               accesskey="N"
               role="button">
              Next
              <br/>
              <span class="smallrellink">
                fatf.transpar...
              </span>
                  <span class="hiddenrellink
                               right-button
                               "
                        data-container="body">
                  fatf.transparency.sklearn.tools.SKLearnExplainer
                  </span>
            </a>
          </div>
        </div>

        

        <!-- Add a citation banner -->
        <div class="alert alert-info" role="alert" style="font-size: 89%; margin-top: 16px;">
          Please <a href="../getting_started/cite.html"><b>cite us</b></a> if you use the software.
        </div>

        <!-- Add a page map -->

        <div class="row toc">
          <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_image_explainers</span></code>.ImageBlimeyLime</a><ul>
<li><a class="reference internal" href="#examples-using-fatf-transparency-predictions-surrogate-image-explainers-imageblimeylime">Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime</span></code></a></li>
</ul>
</li>
</ul>

        </div>

      </div>
    </div>
    

    <div class="col col-sm-10">
      <div class="container">
        <div class="row">
        
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="fatf-transparency-predictions-surrogate-image-explainers-imageblimeylime">
<h1><a class="reference internal" href="../api.html#module-fatf.transparency.predictions.surrogate_image_explainers" title="fatf.transparency.predictions.surrogate_image_explainers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_image_explainers</span></code></a>.ImageBlimeyLime<a class="headerlink" href="#fatf-transparency-predictions-surrogate-image-explainers-imageblimeylime" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime">
<em class="property">class </em><code class="descclassname">fatf.transparency.predictions.surrogate_image_explainers.</code><code class="descname">ImageBlimeyLime</code><span class="sig-paren">(</span><em>image: numpy.ndarray, predictive_model: object, as_probabilistic: bool = True, class_names: Union[List[str], List[int], None] = None, segmentation_mask: Optional[numpy.ndarray] = None, segments_merge_list: Union[None, List[int], List[List[int]]] = None, ratio: float = 0.2, kernel_size: float = 4, max_dist: float = 200, colour: Union[str, int, Tuple[int, int, int], None] = None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/fat-forensics/fat-forensics/blob/f6ce085/fatf/transparency/predictions/surrogate_image_explainers.py#L54"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements a surrogate image explainer equivalent to LIME.</p>
<div class="versionadded">
<p><span class="versionmodified added">New in version 0.1.1.</span></p>
</div>
<p>By default this explainer uses <em>quickshift</em> segmentation
(the <a class="reference internal" href="fatf.utils.data.segmentation.QuickShift.html#fatf.utils.data.segmentation.QuickShift" title="fatf.utils.data.segmentation.QuickShift"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.segmentation.QuickShift</span></code></a> class) and
mean-colour occlusion
(the <a class="reference internal" href="fatf.utils.data.occlusion.Occlusion.html#fatf.utils.data.occlusion.Occlusion" title="fatf.utils.data.occlusion.Occlusion"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.occlusion.Occlusion</span></code></a> class).
It uses the cosine distance transformed thorough the exponential kernel
to generate similarity scores between the binary representation of the
explained instance and the data sample.
It works with both crisp and probabilistic classifiers;
it assumes the latter by default (<code class="docutils literal notranslate"><span class="pre">as_probabilistic=True</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>image</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A numpy array representing an image to be explained.</p>
</dd>
<dt><strong>predictive_model</strong><span class="classifier">object</span></dt><dd><p>A pre-trained (black-box) predictive model to be explained. If
<code class="docutils literal notranslate"><span class="pre">as_probabilistic</span></code> (see below) is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, it must have a
<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method that takes a data set as the only required
input parameter and returns a 2-dimensional numpy array with
probabilities of belonging to each class. Otherwise, if
<code class="docutils literal notranslate"><span class="pre">as_probabilistic</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> must
have a <code class="docutils literal notranslate"><span class="pre">predict</span></code> method that outputs a 1-dimensional array with
(class) predictions.</p>
</dd>
<dt><strong>as_probabilistic</strong><span class="classifier">boolean, optional (default=True)</span></dt><dd><p>A boolean indicating whether the global model is probabilistic. If
<code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> must have a <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>
method. If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> must have a <code class="docutils literal notranslate"><span class="pre">predict</span></code>
method.</p>
</dd>
<dt><strong>class_names</strong><span class="classifier">List[string, integer], optional (default=None)</span></dt><dd><p>A list of strings or integer corresponding to the names of classes.
If the predictive model is probabilistic, the order of the class names
should correspond to the order of columns output by the model.
For crisp models the order is irrelevant.</p>
</dd>
<dt><strong>segmentation_mask</strong><span class="classifier">numpy.ndarray, optional (default=None)</span></dt><dd><p>A numpy array representing an image to be used for generating the
segmentation. If this parameter is not provided, the <code class="docutils literal notranslate"><span class="pre">image</span></code> will
be used to generate the segmentation.</p>
</dd>
<dt><strong>segments_merge_list</strong><span class="classifier">list(integer) or list(list(integer)), optional (default=None)</span></dt><dd><p>A collection or a set of collections of segment ids to be merged.
See the documentation of the
<a class="reference internal" href="fatf.utils.data.segmentation.Segmentation.html#fatf.utils.data.segmentation.Segmentation.merge_segments" title="fatf.utils.data.segmentation.Segmentation.merge_segments"><code class="xref py py-func docutils literal notranslate"><span class="pre">fatf.utils.data.segmentation.Segmentation.merge_segments</span></code></a> method
for more details.</p>
</dd>
<dt><strong>ratio</strong><span class="classifier">number, optional (default=0.2)</span></dt><dd><p>Balances color-space proximity and image-space proximity for
the <strong>quickshift</strong> segmenter.
Higher values give more weight to color-space.
Between 0 and 1.</p>
</dd>
<dt><strong>kernel_size</strong><span class="classifier">number, optional (default=4)</span></dt><dd><p>Width of Gaussian kernel used in smoothing the sample density for
the <strong>quickshift</strong> segmenter.
Higher means fewer clusters.</p>
</dd>
<dt><strong>max_dist</strong><span class="classifier">number, optional (default=200)</span></dt><dd><p>Cut-off point for data distances for the <strong>quickshift</strong> segmenter.
Higher means fewer clusters.</p>
</dd>
<dt><strong>colour</strong><span class="classifier">string, integer, tuple(integer, integer, integer), optional (default=None)</span></dt><dd><p>An occlusion colour specifier.
By default (<code class="docutils literal notranslate"><span class="pre">colour=None</span></code>) the mean colouring strategy is used.
See the documentation of the
<a class="reference internal" href="fatf.utils.data.occlusion.Occlusion.html#fatf.utils.data.occlusion.Occlusion.set_colouring_strategy" title="fatf.utils.data.occlusion.Occlusion.set_colouring_strategy"><code class="xref py py-func docutils literal notranslate"><span class="pre">fatf.utils.data.occlusion.Occlusion.set_colouring_strategy</span></code></a>
method for more details.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>image</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A numpy array representing an image to be explained.</p>
</dd>
<dt><strong>segmentation_mask</strong><span class="classifier">numpy.ndarray</span></dt><dd><p>A numpy array representing an image used to perform segmentation.</p>
</dd>
<dt><strong>segmenter</strong><span class="classifier">fatf.utils.data.segmentation.Segmentation</span></dt><dd><p>A <em>quickshift</em> image segmenter
(<a class="reference internal" href="fatf.utils.data.segmentation.QuickShift.html#fatf.utils.data.segmentation.QuickShift" title="fatf.utils.data.segmentation.QuickShift"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.segmentation.QuickShift</span></code></a>).</p>
</dd>
<dt><strong>occluder</strong><span class="classifier">fatf.utils.data.occlusion.Occlusion</span></dt><dd><p>An image occluder (<a class="reference internal" href="fatf.utils.data.occlusion.Occlusion.html#fatf.utils.data.occlusion.Occlusion" title="fatf.utils.data.occlusion.Occlusion"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.data.occlusion.Occlusion</span></code></a>).</p>
</dd>
<dt><strong>as_probabilistic</strong><span class="classifier">boolean</span></dt><dd><p><code class="docutils literal notranslate"><span class="pre">True</span></code> if the <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> should be treated as
probabilistic and <code class="docutils literal notranslate"><span class="pre">False</span></code> if it should be treated as a classifier.</p>
</dd>
<dt><strong>predictive_model</strong><span class="classifier">object</span></dt><dd><p>A pre-trained (black-box) predictive model to be explained.</p>
</dd>
<dt><strong>predictive_function</strong><span class="classifier">Callable[[numpy.ndarray], numpy.ndarray]</span></dt><dd><p>A function that will be used to get predictions from the explained
predictive model. It references the <code class="docutils literal notranslate"><span class="pre">predictive_model.predict_proba</span></code>
method for for probabilistic models (<code class="docutils literal notranslate"><span class="pre">as_probabilistic=True</span></code>) and the
<code class="docutils literal notranslate"><span class="pre">predictive_model.predict</span></code> method for crisp classifiers.</p>
</dd>
<dt><strong>image_prediction</strong><span class="classifier">Union[string, integer]</span></dt><dd><p>The prediction of the explained image. For probabilistic models it is
the index of the class assigned to this instance by the explained
model; for crisp classifier it is the predicted class.</p>
</dd>
<dt><strong>classes_number</strong><span class="classifier">integer or None</span></dt><dd><p>The number of modelled classes for probabilistic models;
<code class="docutils literal notranslate"><span class="pre">None</span></code> for crisp classifiers unless <code class="docutils literal notranslate"><span class="pre">class_names</span></code> was provided.</p>
</dd>
<dt><strong>class_names</strong><span class="classifier">List[string] or None</span></dt><dd><p>A list of class names that can be predicted by the explained model.
For probabilistic models these are in order they appear in the
probability vector output by the model.
There is no particular order for crisp predictors.</p>
</dd>
<dt><strong>surrogate_data_sample</strong><span class="classifier">numpy.ndarray or None</span></dt><dd><p>A binary data sample generated during the last call of the
<code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method.</p>
</dd>
<dt><strong>surrogate_data_predictions</strong><span class="classifier">numpy.ndarray or None</span></dt><dd><p>Predictions of the explained model for the binary data sample (reversed
to the image representation) generated during the last call of the
<code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method.</p>
</dd>
<dt><strong>similarities</strong><span class="classifier">numpy.ndarray or None</span></dt><dd><p>Similarities between the explained instance and the sampled data
computed in the binary domain using the cosine distance transformed
thorough the exponential kernel and generated during the last call of
the <code class="docutils literal notranslate"><span class="pre">explain_instance</span></code> method.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>IncompatibleModelError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">predictive_model</span></code> does not have the required functionality:
<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method for probabilistic models and <code class="docutils literal notranslate"><span class="pre">predict</span></code>
method crisp classifiers.</p>
</dd>
<dt><strong>RuntimeError</strong></dt><dd><p>The number of class names provided via the <code class="docutils literal notranslate"><span class="pre">class_names</span></code> parameter
does not agree with the number of classes output by the probabilistic
model.</p>
</dd>
<dt><strong>TypeError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">as_probabilistic</span></code> parameter is not a boolean.
The <code class="docutils literal notranslate"><span class="pre">class_names</span></code> parameter is neither a list nor <code class="docutils literal notranslate"><span class="pre">None</span></code>.
Some of the elements in the <code class="docutils literal notranslate"><span class="pre">class_names</span></code> list are neither a string
nor an integer.</p>
</dd>
<dt><strong>ValueError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">class_names</span></code> list is empty or it contains duplicates.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-center">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.explain_instance" title="fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.explain_instance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explain_instance</span></code></a>(explained_class, str, …)</p></td>
<td><p>Explains the image used to initialise this class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.set_occlusion_colour" title="fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.set_occlusion_colour"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_occlusion_colour</span></code></a>(colour)</p></td>
<td><p>Sets the occlusion colour.</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.explain_instance">
<code class="descname">explain_instance</code><span class="sig-paren">(</span><em>explained_class: Union[int, str, None] = None, samples_number: int = 50, batch_size: int = 50, kernel_width: float = 0.25, colour: Union[str, int, Tuple[int, int, int], None] = None, reuse_sample: bool = False, return_model: bool = False</em><span class="sig-paren">)</span> &#x2192; Union[Dict[str, numbers.Number], Tuple[Dict[str, numbers.Number], fatf.utils.models.models.Model]]<a class="reference external" href="https://github.com/fat-forensics/fat-forensics/blob/f6ce085/fatf/transparency/predictions/surrogate_image_explainers.py#L315"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.explain_instance" title="Permalink to this definition">¶</a></dt>
<dd><p>Explains the image used to initialise this class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>explained_class</strong><span class="classifier">Union[integer, string], optional (default=None)</span></dt><dd><p>The class to be explained. By default (<code class="docutils literal notranslate"><span class="pre">explained_class=None</span></code>)
the class predicted by the explained model for the explained image
will be used.
For probabilistic models this can be the index of the class in the
probability vector output by the explained model or the name of the
class if <code class="docutils literal notranslate"><span class="pre">class_names</span></code> parameter was provided while initialising
this class.
For crisp classifiers this has to be one of the values predicted by
the explained model.</p>
</dd>
<dt><strong>samples_number</strong><span class="classifier">integer, optional (default=50)</span></dt><dd><p>The number of data points sampled from the random binary generator
to be used for fitting the local surrogate model.</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">integer, optional (default=50)</span></dt><dd><p>The number of images to be processed in one iteration. Since this
step is computationally expensive – images need to be generated
and occluded according to the binary data sample, and then
predicted by the explained model – the data points can be
processed in fixed-size batches.</p>
</dd>
<dt><strong>kernel_width</strong><span class="classifier">float, optional (default=0.25)</span></dt><dd><p>The width of the exponential kernel used when computing weights of
the binary sampled data based on the cosine distances between them
and the explained image.</p>
</dd>
<dt><strong>colour</strong><span class="classifier">string, integer, tuple(integer, integer, integer), optional (default=None)</span></dt><dd><p>An occlusion colour specifier.
By default (<code class="docutils literal notranslate"><span class="pre">colour=None</span></code>) the colour specified when initialising
this class is used.
See the documentation of the
<a class="reference internal" href="fatf.utils.data.occlusion.Occlusion.html#fatf.utils.data.occlusion.Occlusion.set_colouring_strategy" title="fatf.utils.data.occlusion.Occlusion.set_colouring_strategy"><code class="xref py py-func docutils literal notranslate"><span class="pre">fatf.utils.data.occlusion.Occlusion.set_colouring_strategy</span></code></a>
method for more details.</p>
</dd>
<dt><strong>reuse_sample</strong><span class="classifier">boolean, optional (default=False)</span></dt><dd><p>Whether to generate a new binary data sample or reuse the one
generated with the last call of this method.</p>
</dd>
<dt><strong>return_models</strong><span class="classifier">boolean, optional (default=False)</span></dt><dd><p>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, this method will return both the feature importance
explanation and the local surrogate model.
Otherwise, only the explanation is returned.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>explanations</strong><span class="classifier">Dictionary[string, float]</span></dt><dd><p>A dictionary containing image segment importance (extracted
from the local linear surrogate).</p>
</dd>
<dt><strong>models</strong><span class="classifier">sklearn.linear_model.base.LinearModel, optional</span></dt><dd><p>A locally fitted surrogate linear model.
This model is only returned when <code class="docutils literal notranslate"><span class="pre">return_model=True</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>IndexError</strong></dt><dd><p>The name of the class chosen to be explained could not be located
among the class names provided upon initialising this object.
The index of the explained class – when explaining a probabilistic
model – is invalid.</p>
</dd>
<dt><strong>RuntimeError</strong></dt><dd><p>Some of the cosine distances could not be computed due to a
numerical error.
The data sample cannot be reused without calling this method at
least once beforehand.
A class name cannot be used when explaining a probabilistic model
without initialising this object with class names.</p>
</dd>
<dt><strong>TypeError</strong></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">return_model</span></code> or <code class="docutils literal notranslate"><span class="pre">reuse_sample</span></code> parameter is not a
boolean.
The <code class="docutils literal notranslate"><span class="pre">explained_class</span></code> parameter is neither of <code class="docutils literal notranslate"><span class="pre">None</span></code>, a string
or an integer.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Warns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>UserWarning</strong></dt><dd><p>Informs the user if none of the sampled data were predicted with
the explained class when explaining a crisp model – such a
situation will most probably result in unreliable explanations.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.set_occlusion_colour">
<code class="descname">set_occlusion_colour</code><span class="sig-paren">(</span><em>colour</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/fat-forensics/fat-forensics/blob/f6ce085/fatf/transparency/predictions/surrogate_image_explainers.py#L305"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.set_occlusion_colour" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the occlusion colour.</p>
<p>See the documentation of the
<a class="reference internal" href="fatf.utils.data.occlusion.Occlusion.html#fatf.utils.data.occlusion.Occlusion.set_colouring_strategy" title="fatf.utils.data.occlusion.Occlusion.set_colouring_strategy"><code class="xref py py-func docutils literal notranslate"><span class="pre">fatf.utils.data.occlusion.Occlusion.set_colouring_strategy</span></code></a>
method for more details.</p>
</dd></dl>

</dd></dl>

<section id="examples-using-fatf-transparency-predictions-surrogate-image-explainers-imageblimeylime">
<h2>Examples using <code class="docutils literal notranslate"><span class="pre">fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime</span></code><a class="headerlink" href="#examples-using-fatf-transparency-predictions-surrogate-image-explainers-imageblimeylime" title="Permalink to this headline">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the LIME image explainer to explain a prediction."><figure class="align-center" id="id1">
<img alt="../_images/sphx_glr_xmpl_transparency_lime_image_thumb.png" src="../_images/sphx_glr_xmpl_transparency_lime_image_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../sphinx_gallery_auto/transparency/xmpl_transparency_lime_image.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-lime-image-py"><span class="std std-ref">Using LIME Image Explainer</span></a></span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="clear:both"></div></section>
</section>


          </div>
        </div>
      </div>
        </div>
      </div>
    </div>
  </div>
</div>

  <div class="container cusotm-footer">
    <div class="row">
      <div class="col-3">
        &copy; 2018--2023, Kacper Sokol et al.
      </div>
      <div class="col-6">
        <a class="footer-img-link" href="contributors.html#funding">
          <img src="../_static/img/bristol.svg" title="Univeristy of Bristol" style="max-height: 30px">
          &nbsp;
          <img src="../_static/img/thales.svg" title="Thales" style="max-height: 20px">
        </a>
        <br>
        <a href="contributors.html#funding" style="top: 4px; position: relative;">
          More information on our contributors
        </a>
      </div>
      <div class="col-3">
        <a href="../_sources/generated/fatf.transparency.predictions.surrogate_image_explainers.ImageBlimeyLime.rst.txt" rel="nofollow">
          Show this page source
        </a>
      </div>
    </div>
  </div>

  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FHEM8Y8CHX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FHEM8Y8CHX');
  </script>
  

  
  <script>
    (function() {
      var cx = '014039732624725851926:mpducezglrq';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
  
  </body>
</html>