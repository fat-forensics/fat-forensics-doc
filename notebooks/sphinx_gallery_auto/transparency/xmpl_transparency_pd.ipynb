{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using Partial Dependence Explainer\n\n\nThis example illustrates how to use the Partial Dependence (PD) explainer and\nits plotting function. This example only shows how to get the PD array straight\nfrom the data. The calculation of PD required to compute the Individual\nConditional Expectation (ICE) as part of the process. By using the\n:func:`fatf.transparency.models.feature_influence.partial_dependence` function\nthe ICE array is computed, however it is never returned back to the user. If\nyou want to inspect both ICE and PD then please have a look at the\n`sphx_glr_sphinx_gallery_auto_transparency_xmpl_transparency_pd.py`\nexample and the two following functions:\n\n* :func:`fatf.transparency.models.feature_influence.individual_conditional_expectation`,\n* :func:`fatf.transparency.models.feature_influence.partial_dependence_ice`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Kacper Sokol <k.sokol@bristol.ac.uk>\n# License: new BSD\n\nimport fatf.utils.data.datasets as fatf_datasets\nimport fatf.utils.models as fatf_models\n\nimport fatf.transparency.models.feature_influence as fatf_fi\n\nimport fatf.vis.feature_influence as fatf_vis_fi\n\nprint(__doc__)\n\n# Load data\niris_data_dict = fatf_datasets.load_iris()\niris_X = iris_data_dict['data']\niris_y = iris_data_dict['target'].astype(int)\niris_feature_names = iris_data_dict['feature_names']\niris_class_names = iris_data_dict['target_names']\n\n# Train a model\nclf = fatf_models.KNN()\nclf.fit(iris_X, iris_y)\n\n# Select a feature to be explained\nselected_feature_index = 1\nselected_feature_name = iris_feature_names[selected_feature_index]\nprint('Explaining feature (index: {}): {}.'.format(selected_feature_index,\n                                                   selected_feature_name))\n\n# Select class for which the explanation will be produced\nexplanation_class = 2\nexplanation_class_name = iris_class_names[explanation_class]\nprint('Explaining class (index: {}): {}.'.format(explanation_class,\n                                                 explanation_class_name))\n\n# Define the number of samples to be generated (granularity of the explanation)\nlinspace_samples = 25\n\n# Calculate Partial Dependence\npd_array, pd_linspace = fatf_fi.partial_dependence(\n    iris_X, clf, selected_feature_index, steps_number=linspace_samples)\n\n# Plot Partial Dependence on its own\npd_plot_clean = fatf_vis_fi.plot_partial_dependence(\n    pd_array,\n    pd_linspace,\n    explanation_class,\n    class_name=explanation_class_name,\n    feature_name=selected_feature_name)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}