

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
  
    <title>Measuring Fairness of a Predictive Model – Disparate Impact &#8212; FAT Forensics 0.1.0 documentation</title>
  <!-- html title is before nature.css - we use this hack to load bootstrap first -->
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css">

    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="canonical" href="https://fat-forensics.org/sphinx_gallery_auto/fairness/xmpl_fairness_models_measure.html" />
    <link rel="shortcut icon" href="../../_static/fatf.ico"/>
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Measuring Fairness of a Prediction – Counterfactual Fairness" href="xmpl_fairness_predictions_measure.html" />
    <link rel="prev" title="Measuring Robustness of a Prediction – Data Density" href="../accountability/xmpl_accountability_predictions_density.html" />
  <!-- jQuery first, then Bootstrap JS -->
  <!-- jQuery is distributed with Sphinx already -->
  <!-- <script src="../../_static/jquery.min.js"></script> -->
  <script src="../../_static/js/bootstrap.min.js"></script>

  </head><body>
<div class="container">
  <nav class="navbar navbar-expand-md navbar-light bg-light">
    <a class="navbar-brand align-text-middle" href="../../index.html">
      <img src="../../_static/fatf.png"
       alt="Logo"
       width="35" height="35"
       class="d-inline-block align-middle">
      FAT Forensics
    </a>

    <button class="navbar-toggler"
            type="button"
            data-toggle="collapse"
            data-target="#navbarCollapsedContent">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse"
         id="navbarCollapsedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="../../index.html">Home</a>
        </li>

        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" role="button" data-toggle="dropdown">
            Documentation
          </a>
          <div class="dropdown-menu">
            <div class="dropdown-header">FAT Forensics</div>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../../getting_started/index.html">Getting Started</a>
            <a class="dropdown-item" href="../../tutorials/index.html">Tutorials</a>
            <a class="dropdown-item" href="../index.html">Examples</a>
            <a class="dropdown-item" href="../../api.html">API Reference</a>
            <a class="dropdown-item" href="../../how_to/index.html">How-To Guides</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../../news.html">News</a>
            <a class="dropdown-item" href="../../development.html">Developers Guide</a>
            <a class="dropdown-item" href="../../contributors.html">Contributors</a>
            <a class="dropdown-item" href="../../changelog.html">Changelog</a>
            <a class="dropdown-item" href="../../roadmap.html">Roadmap</a>
          </div>
        </li>

        <li class="nav-item">
          <a class="nav-link" href="../../user_guide/index.html">
            FAT User Guide
          </a>
        </li>
      </ul>

      <div class="search_form form-inline">
          <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div>
  </nav>
</div>

<!-- GitHub "fork me" ribbon -->
<!--
<a href="https://github.com/fat-forensics/fat-forensics">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>
-->
<span id="forkongithub">
  <a href="https://github.com/fat-forensics/fat-forensics">
    Fork me on GitHub
  </a>
</span>
<div class="container">
  <div class="row">
    <div class="col-sm-2">
      <div class="container sidebar">
        <!--
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/fatf.png" alt="Logo"/>
            </a></p>
  <h3><a href="../../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Measuring Fairness of a Predictive Model – Disparate Impact</a><ul>
<li><a class="reference internal" href="#equal-accuracy">Equal Accuracy</a></li>
<li><a class="reference internal" href="#equal-opportunity">Equal Opportunity</a></li>
<li><a class="reference internal" href="#demographic-parity">Demographic Parity</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../accountability/xmpl_accountability_predictions_density.html"
                        title="previous chapter">Measuring Robustness of a Prediction – Data Density</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="xmpl_fairness_predictions_measure.html"
                        title="next chapter">Measuring Fairness of a Prediction – Counterfactual Fairness</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/sphinx_gallery_auto/fairness/xmpl_fairness_models_measure.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>-->
        <!-- Add a link to the 'up' page -->
        <div class="row rel">
          <div class="col rellink pad-b-1">
            <a class="btn btn-primary btn-sm"
               href="../index.html"
               role="button">
              Up
              <br/>
              <span class="smallrellink">
                Examples
              </span>
              <span class="hiddenrellink left-button">
                Examples
              </span>
              
            </a>
          </div>
        </div>

        <!-- Add a links to the 'relative' pages -->

        <div class="row rel">
          <div class="col-6 rellink
                      pad-r-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="../accountability/xmpl_accountability_predictions_density.html"
               accesskey="P"
               role="button">
              Previous
              <br/>
              <span class="smallrellink">
                Measuring Rob...
              </span>
                  <span class="hiddenrellink
                               left-button
                               "
                        data-container="body">
                  Measuring Robustness of a Prediction – Data Density
                  </span>
            </a>
          </div>
          <div class="col-6 rellink
                      pad-l-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="xmpl_fairness_predictions_measure.html"
               accesskey="N"
               role="button">
              Next
              <br/>
              <span class="smallrellink">
                Measuring Fai...
              </span>
                  <span class="hiddenrellink
                               right-button
                               "
                        data-container="body">
                  Measuring Fairness of a Prediction – Counterfactual Fairness
                  </span>
            </a>
          </div>
        </div>

        

        <!-- Add a citation banner -->
        <div class="alert alert-info" role="alert" style="font-size: 89%; margin-top: 16px;">
          Please <a href="../../getting_started/cite.html"><b>cite us</b></a> if you use the software.
        </div>

        <!-- Add a page map -->

        <div class="row toc">
          <ul>
<li><a class="reference internal" href="#">Measuring Fairness of a Predictive Model – Disparate Impact</a><ul>
<li><a class="reference internal" href="#equal-accuracy">Equal Accuracy</a></li>
<li><a class="reference internal" href="#equal-opportunity">Equal Opportunity</a></li>
<li><a class="reference internal" href="#demographic-parity">Demographic Parity</a></li>
</ul>
</li>
</ul>

        </div>

      </div>
    </div>
    

    <div class="col col-sm-10">
      <div class="container">
        <div class="row">
        
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-sphinx-gallery-auto-fairness-xmpl-fairness-models-measure-py"><span class="std std-ref">here</span></a> to download the full example code or run this example in your browser via Binder</p>
</div>
<div class="sphx-glr-example-title section" id="measuring-fairness-of-a-predictive-model-disparate-impact">
<span id="sphx-glr-sphinx-gallery-auto-fairness-xmpl-fairness-models-measure-py"></span><h1>Measuring Fairness of a Predictive Model – Disparate Impact<a class="headerlink" href="#measuring-fairness-of-a-predictive-model-disparate-impact" title="Permalink to this headline">¶</a></h1>
<p>This example illustrates how to measure Disparate Impact of a predictive model.
In this example we measure the three most common Disparate Impact measures:</p>
<ul class="simple">
<li><p>Equal Accuracy;</p></li>
<li><p>Equal Opportunity; and</p></li>
<li><p>Demographic Parity.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Our implementation of the k-nearest neighbours model
(<a class="reference internal" href="../../generated/fatf.utils.models.models.KNN.html#fatf.utils.models.models.KNN" title="fatf.utils.models.models.KNN"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.models.models.KNN</span></code></a>) works with structured numpy arrays,
therefore we do not have to pre-process (e.g., one-hot encode) the
categorical (stirng-based) features.</p>
<blockquote>
<div><p>For scikit-learn models all of the categorical features in the data set
would need to be pre-processed first.</p>
</div></blockquote>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Author: Kacper Sokol &lt;k.sokol@bristol.ac.uk&gt;</span>
<span class="c1"># License: new BSD</span>

<span class="kn">import</span> <span class="nn">fatf.utils.data.datasets</span> <span class="k">as</span> <span class="nn">fatf_datasets</span>
<span class="kn">import</span> <span class="nn">fatf.utils.models</span> <span class="k">as</span> <span class="nn">fatf_models</span>

<span class="kn">import</span> <span class="nn">fatf.fairness.models.measures</span> <span class="k">as</span> <span class="nn">fatf_mfm</span>

<span class="kn">import</span> <span class="nn">fatf.utils.metrics.tools</span> <span class="k">as</span> <span class="nn">fatf_mt</span>

<span class="nb">print</span><span class="p">(</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="c1"># Load data</span>
<span class="n">hr_data_dict</span> <span class="o">=</span> <a href="../../generated/fatf.utils.data.datasets.load_health_records.html#fatf.utils.data.datasets.load_health_records" title="View documentation for fatf.utils.data.datasets.load_health_records"><span class="n">fatf_datasets</span><span class="o">.</span><span class="n">load_health_records</span></a><span class="p">()</span>
<span class="n">hr_X</span> <span class="o">=</span> <span class="n">hr_data_dict</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">hr_y</span> <span class="o">=</span> <span class="n">hr_data_dict</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">hr_feature_names</span> <span class="o">=</span> <span class="n">hr_data_dict</span><span class="p">[</span><span class="s1">&#39;feature_names&#39;</span><span class="p">]</span>
<span class="n">hr_class_names</span> <span class="o">=</span> <span class="n">hr_data_dict</span><span class="p">[</span><span class="s1">&#39;target_names&#39;</span><span class="p">]</span>

<span class="c1"># Train a model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">fatf_models</span><span class="o">.</span><span class="n">KNN</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">hr_X</span><span class="p">,</span> <span class="n">hr_y</span><span class="p">)</span>

<span class="c1"># Get predictions of the model for the fairness evaluation (which is also the</span>
<span class="c1"># training data in this example)</span>
<span class="n">hr_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">hr_X</span><span class="p">)</span>

<span class="c1"># Select a protected feature</span>
<span class="n">protected_feature</span> <span class="o">=</span> <span class="s1">&#39;gender&#39;</span>

<span class="c1"># Get a confusion matrix for all sub-groups according to the split feature</span>
<span class="n">confusion_matrix_per_bin</span><span class="p">,</span> <span class="n">bin_names</span> <span class="o">=</span> <a href="../../generated/fatf.utils.metrics.tools.confusion_matrix_per_subgroup.html#fatf.utils.metrics.tools.confusion_matrix_per_subgroup" title="View documentation for fatf.utils.metrics.tools.confusion_matrix_per_subgroup"><span class="n">fatf_mt</span><span class="o">.</span><span class="n">confusion_matrix_per_subgroup</span></a><span class="p">(</span>
    <span class="n">hr_X</span><span class="p">,</span> <span class="n">hr_y</span><span class="p">,</span> <span class="n">hr_pred</span><span class="p">,</span> <span class="n">protected_feature</span><span class="p">,</span> <span class="n">treat_as_categorical</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">print_fairness</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_matrix</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Prints out which sub-populations violate a group fairness metric.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The *</span><span class="si">{}</span><span class="s1">* group-based fairness metric for *</span><span class="si">{}</span><span class="s1">* feature split &#39;</span>
          <span class="s1">&#39;are:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">protected_feature</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">grouping_i</span><span class="p">,</span> <span class="n">grouping_name_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bin_names</span><span class="p">):</span>
        <span class="n">j_offset</span> <span class="o">=</span> <span class="n">grouping_i</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">grouping_j</span><span class="p">,</span> <span class="n">grouping_name_j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">bin_names</span><span class="p">[</span><span class="n">j_offset</span><span class="p">:]):</span>
            <span class="n">grouping_j</span> <span class="o">+=</span> <span class="n">j_offset</span>
            <span class="n">is_not</span> <span class="o">=</span> <span class="s1">&#39; &gt;not&lt;&#39;</span> <span class="k">if</span> <span class="n">metric_matrix</span><span class="p">[</span><span class="n">grouping_i</span><span class="p">,</span> <span class="n">grouping_j</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>

            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;    * The fairness metric is</span><span class="si">{}</span><span class="s1"> satisfied for &quot;</span><span class="si">{}</span><span class="s1">&quot; and &quot;</span><span class="si">{}</span><span class="s1">&quot; &#39;</span>
                  <span class="s1">&#39;sub-populations.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">is_not</span><span class="p">,</span> <span class="n">grouping_name_i</span><span class="p">,</span>
                                            <span class="n">grouping_name_j</span><span class="p">))</span>
</pre></div>
</div>
<div class="section" id="equal-accuracy">
<h2>Equal Accuracy<a class="headerlink" href="#equal-accuracy" title="Permalink to this headline">¶</a></h2>
<p>First, let’s measure whether the model is fair according to the Equal
Accuracy metric.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the Equal Accuracy binary matrix</span>
<span class="n">equal_accuracy_matrix</span> <span class="o">=</span> <a href="../../generated/fatf.fairness.models.measures.equal_accuracy.html#fatf.fairness.models.measures.equal_accuracy" title="View documentation for fatf.fairness.models.measures.equal_accuracy"><span class="n">fatf_mfm</span><span class="o">.</span><span class="n">equal_accuracy</span></a><span class="p">(</span><span class="n">confusion_matrix_per_bin</span><span class="p">)</span>

<span class="c1"># Print out fairness</span>
<span class="n">print_fairness</span><span class="p">(</span><span class="s1">&#39;Equal Accuracy&#39;</span><span class="p">,</span> <span class="n">equal_accuracy_matrix</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The *Equal Accuracy* group-based fairness metric for *gender* feature split are:
    * The fairness metric is satisfied for &quot;(&#39;female&#39;,)&quot; and &quot;(&#39;male&#39;,)&quot; sub-populations.
</pre></div>
</div>
</div>
<div class="section" id="equal-opportunity">
<h2>Equal Opportunity<a class="headerlink" href="#equal-opportunity" title="Permalink to this headline">¶</a></h2>
<p>Now, let’s see whether the model is fair according to the Equal Opportunity
metric.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the Equal Opportunity binary matrix</span>
<span class="n">equal_opportunity_matrix</span> <span class="o">=</span> <a href="../../generated/fatf.fairness.models.measures.equal_opportunity.html#fatf.fairness.models.measures.equal_opportunity" title="View documentation for fatf.fairness.models.measures.equal_opportunity"><span class="n">fatf_mfm</span><span class="o">.</span><span class="n">equal_opportunity</span></a><span class="p">(</span><span class="n">confusion_matrix_per_bin</span><span class="p">)</span>

<span class="c1"># Print out fairness</span>
<span class="n">print_fairness</span><span class="p">(</span><span class="s1">&#39;Equal Opportunity&#39;</span><span class="p">,</span> <span class="n">equal_opportunity_matrix</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The *Equal Opportunity* group-based fairness metric for *gender* feature split are:
    * The fairness metric is satisfied for &quot;(&#39;female&#39;,)&quot; and &quot;(&#39;male&#39;,)&quot; sub-populations.
</pre></div>
</div>
</div>
<div class="section" id="demographic-parity">
<h2>Demographic Parity<a class="headerlink" href="#demographic-parity" title="Permalink to this headline">¶</a></h2>
<p>Finally, let’s measure the Demographic Parity of the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the Demographic Parity binary matrix</span>
<span class="n">demographic_parity_matrix</span> <span class="o">=</span> <a href="../../generated/fatf.fairness.models.measures.demographic_parity.html#fatf.fairness.models.measures.demographic_parity" title="View documentation for fatf.fairness.models.measures.demographic_parity"><span class="n">fatf_mfm</span><span class="o">.</span><span class="n">demographic_parity</span></a><span class="p">(</span>
    <span class="n">confusion_matrix_per_bin</span><span class="p">)</span>

<span class="c1"># Print out fairness</span>
<span class="n">print_fairness</span><span class="p">(</span><span class="s1">&#39;Demographic Parity&#39;</span><span class="p">,</span> <span class="n">demographic_parity_matrix</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>The *Demographic Parity* group-based fairness metric for *gender* feature split are:
    * The fairness metric is &gt;not&lt; satisfied for &quot;(&#39;female&#39;,)&quot; and &quot;(&#39;male&#39;,)&quot; sub-populations.
</pre></div>
</div>
<hr class="docutils" />
<p>Based on these results we can easily see that <strong>Demographic Parity</strong> is the
only fairness metric that is violated.</p>
<hr class="docutils" />
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.068 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-sphinx-gallery-auto-fairness-xmpl-fairness-models-measure-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/fat-forensics/fat-forensics-doc/master?filepath=notebooks/sphinx_gallery_auto/fairness/xmpl_fairness_models_measure.ipynb"><img alt="https://mybinder.org/badge_logo.svg" src="https://mybinder.org/badge_logo.svg" width="150px" /></a>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/9c29922fd8b510b1976ac72387761acf/xmpl_fairness_models_measure.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">xmpl_fairness_models_measure.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/927c491c786a15a8dc18c5a2d2cb2072/xmpl_fairness_models_measure.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">xmpl_fairness_models_measure.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


          </div>
        </div>
      </div>
        </div>
      </div>
    </div>
  </div>
</div>

  <div class="container cusotm-footer">
    <div class="row">
      <div class="col-3">
        &copy; 2018--2020, Kacper Sokol et al.
      </div>
      <div class="col-6">
        <a class="footer-img-link" href="contributors.html#funding">
          <img src="../../_static/img/bristol.svg" title="Univeristy of Bristol" style="max-height: 30px">
          &nbsp;
          <img src="../../_static/img/thales.svg" title="Thales" style="max-height: 20px">
        </a>
        <br>
        <a href="contributors.html#funding" style="top: 4px; position: relative;">
          More information on our contributors
        </a>
      </div>
      <div class="col-3">
        <a href="../../_sources/sphinx_gallery_auto/fairness/xmpl_fairness_models_measure.rst.txt" rel="nofollow">
          Show this page source
        </a>
      </div>
    </div>
  </div>

  
  <script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-142154492-1', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  
  <script>
    (function() {
      var cx = '014039732624725851926:mpducezglrq';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
  
  </body>
</html>