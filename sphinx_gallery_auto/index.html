

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  
    <title>Examples &#8212; FAT Forensics 0.1.2 documentation</title>
  <!-- html title is before nature.css - we use this hack to load bootstrap first -->
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="../_static/css/bootstrap.min.css">

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="canonical" href="https://fat-forensics.org/sphinx_gallery_auto/index.html" />
    <link rel="shortcut icon" href="../_static/fatf.ico"/>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Measuring Robustness of a Data Set – Sampling Bias" href="accountability/xmpl_accountability_data_measure.html" />
    <link rel="prev" title="Explaining Machine Learning Predictions: LIME and Counterfactuals" href="../tutorials/prediction-explainability.html" />
  <!-- jQuery first, then Bootstrap JS -->
  <!-- jQuery is distributed with Sphinx already -->
  <!-- <script src="../_static/jquery.min.js"></script> -->
  <script src="../_static/js/bootstrap.min.js"></script>

  </head><body>
<div class="container">
  <nav class="navbar navbar-expand-md navbar-light bg-light">
    <a class="navbar-brand align-text-middle" href="../index.html">
      <img src="../_static/fatf.png"
       alt="Logo"
       width="35" height="35"
       class="d-inline-block align-middle">
      FAT Forensics
    </a>

    <button class="navbar-toggler"
            type="button"
            data-toggle="collapse"
            data-target="#navbarCollapsedContent">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse"
         id="navbarCollapsedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="../index.html">Home</a>
        </li>

        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" role="button" data-toggle="dropdown">
            Documentation
          </a>
          <div class="dropdown-menu">
            <div class="dropdown-header">FAT Forensics</div>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../getting_started/index.html">Getting Started</a>
            <a class="dropdown-item" href="../tutorials/index.html">Tutorials</a>
            <a class="dropdown-item" href="#">Examples</a>
            <a class="dropdown-item" href="../api.html">API Reference</a>
            <a class="dropdown-item" href="../how_to/index.html">How-To Guides</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="../news.html">News</a>
            <a class="dropdown-item" href="../development.html">Developers Guide</a>
            <a class="dropdown-item" href="../contributors.html">Contributors</a>
            <a class="dropdown-item" href="../changelog.html">Changelog</a>
            <a class="dropdown-item" href="../roadmap.html">Roadmap</a>
          </div>
        </li>

        <li class="nav-item">
          <a class="nav-link" href="../user_guide/index.html">
            FAT User Guide
          </a>
        </li>
      </ul>

      <div class="search_form form-inline">
          <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div>
  </nav>
</div>

<!-- GitHub "fork me" ribbon -->
<!--
<a href="https://github.com/fat-forensics/fat-forensics">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>
-->
<span id="forkongithub">
  <a href="https://github.com/fat-forensics/fat-forensics">
    Fork me on GitHub
  </a>
</span>
<div class="container">
  <div class="row">
    <div class="col-sm-2">
      <div class="container sidebar">
        <!--
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/fatf.png" alt="Logo"/>
            </a></p>
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Examples</a></li>
<li><a class="reference internal" href="#accountability-examples">Accountability Examples</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#fairness-examples">Fairness Examples</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#transparency-examples">Transparency Examples</a><ul>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="../tutorials/prediction-explainability.html"
                        title="previous chapter">Explaining Machine Learning Predictions: LIME and Counterfactuals</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="accountability/xmpl_accountability_data_measure.html"
                        title="next chapter">Measuring Robustness of a Data Set – Sampling Bias</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/sphinx_gallery_auto/index.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>-->
        <!-- Add a link to the 'up' page -->

        <!-- Add a links to the 'relative' pages -->

        <div class="row rel">
          <div class="col-6 rellink
                      pad-r-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="../tutorials/prediction-explainability.html"
               accesskey="P"
               role="button">
              Previous
              <br/>
              <span class="smallrellink">
                Explaining Ma...
              </span>
                  <span class="hiddenrellink
                               left-button
                               "
                        data-container="body">
                  Explaining Machine Learning Predictions: LIME and Counterfactuals
                  </span>
            </a>
          </div>
          <div class="col-6 rellink
                      pad-l-1
                      ">
            <a class="btn btn-primary btn-sm"
               href="accountability/xmpl_accountability_data_measure.html"
               accesskey="N"
               role="button">
              Next
              <br/>
              <span class="smallrellink">
                Measuring Rob...
              </span>
                  <span class="hiddenrellink
                               right-button
                               "
                        data-container="body">
                  Measuring Robustness of a Data Set – Sampling Bias
                  </span>
            </a>
          </div>
        </div>

        

        <!-- Add a citation banner -->
        <div class="alert alert-info" role="alert" style="font-size: 89%; margin-top: 16px;">
          Please <a href="../getting_started/cite.html"><b>cite us</b></a> if you use the software.
        </div>

        <!-- Add a page map -->

        <div class="row toc">
          <ul>
<li><a class="reference internal" href="#">Examples</a></li>
<li><a class="reference internal" href="#accountability-examples">Accountability Examples</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#fairness-examples">Fairness Examples</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#transparency-examples">Transparency Examples</a><ul>
</ul>
</li>
</ul>

        </div>

      </div>
    </div>
    

    <div class="col col-sm-10">
      <div class="container">
        <div class="row">
        
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="examples">
<span id="sphx-glr-sphinx-gallery-auto"></span><span id="id1"></span><h1>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<p>Here you can find various examples of using FAT Forensics.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please note that all of the examples using the
<a class="reference internal" href="../generated/fatf.utils.models.models.KNN.html#fatf.utils.models.models.KNN" title="fatf.utils.models.models.KNN"><code class="xref py py-class docutils literal notranslate"><span class="pre">fatf.utils.models.models.KNN</span></code></a> model class may be slow as our
implementation of the k-nearest neighbours algorithm is in pure Python,
hence is rather slow.</p>
</div>
<div style='clear:both'></div></section>
<section id="accountability-examples">
<span id="sphx-glr-sphinx-gallery-auto-accountability"></span><span id="id2"></span><h1>Accountability Examples<a class="headerlink" href="#accountability-examples" title="Permalink to this headline">¶</a></h1>
<p>Here you can find various examples of how to use FAT Forensics to evaluate
accountability – <em>security</em>, <em>safety</em>, <em>robustness</em> and <em>privacy</em> – of data
sets, machine learning models and their predictions.</p>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to identify Sampling Bias for a data set grouping for a selected f..."><figure class="align-center" id="id5">
<img alt="../_images/sphx_glr_xmpl_accountability_data_measure_thumb.png" src="../_images/sphx_glr_xmpl_accountability_data_measure_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="accountability/xmpl_accountability_data_measure.html#sphx-glr-sphinx-gallery-auto-accountability-xmpl-accountability-data-measure-py"><span class="std std-ref">Measuring Robustness of a Data Set – Sampling Bias</span></a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to measure Systematic Performance Bias based on a selected predict..."><figure class="align-center" id="id6">
<img alt="../_images/sphx_glr_xmpl_accountability_models_measure_thumb.png" src="../_images/sphx_glr_xmpl_accountability_models_measure_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="accountability/xmpl_accountability_models_measure.html#sphx-glr-sphinx-gallery-auto-accountability-xmpl-accountability-models-measure-py"><span class="std std-ref">Measuring Robustness of a Predictive Model – Systematic Performance Bias</span></a></span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use a data density estimation to &quot;measure&quot; to what extent a pre..."><figure class="align-center" id="id7">
<img alt="../_images/sphx_glr_xmpl_accountability_predictions_density_thumb.png" src="../_images/sphx_glr_xmpl_accountability_predictions_density_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="accountability/xmpl_accountability_predictions_density.html#sphx-glr-sphinx-gallery-auto-accountability-xmpl-accountability-predictions-density-py"><span class="std std-ref">Measuring Robustness of a Prediction – Data Density</span></a></span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div style='clear:both'></div></section>
<section id="fairness-examples">
<span id="sphx-glr-sphinx-gallery-auto-fairness"></span><span id="id3"></span><h1>Fairness Examples<a class="headerlink" href="#fairness-examples" title="Permalink to this headline">¶</a></h1>
<p>Here you can find various examples of how to use FAT Forensics to evaluate and
mitigate a range of fairness aspects of data sets, machine learning models and
their predictions.</p>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to measure Disparate Impact of a predictive model. In this example..."><figure class="align-center" id="id8">
<img alt="../_images/sphx_glr_xmpl_fairness_models_measure_thumb.png" src="../_images/sphx_glr_xmpl_fairness_models_measure_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="fairness/xmpl_fairness_models_measure.html#sphx-glr-sphinx-gallery-auto-fairness-xmpl-fairness-models-measure-py"><span class="std std-ref">Measuring Fairness of a Predictive Model – Disparate Impact</span></a></span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how scrutinise a data point under the counterfactual fairness assumpti..."><figure class="align-center" id="id9">
<img alt="../_images/sphx_glr_xmpl_fairness_predictions_measure_thumb.png" src="../_images/sphx_glr_xmpl_fairness_predictions_measure_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="fairness/xmpl_fairness_predictions_measure.html#sphx-glr-sphinx-gallery-auto-fairness-xmpl-fairness-predictions-measure-py"><span class="std std-ref">Measuring Fairness of a Prediction – Counterfactual Fairness</span></a></span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to find unfair rows in a data set using the :func:`fatf.fairness.d..."><figure class="align-center" id="id10">
<img alt="../_images/sphx_glr_xmpl_fairness_data_measure_thumb.png" src="../_images/sphx_glr_xmpl_fairness_data_measure_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="fairness/xmpl_fairness_data_measure.html#sphx-glr-sphinx-gallery-auto-fairness-xmpl-fairness-data-measure-py"><span class="std std-ref">Measuring Fairness of a Data Set</span></a></span><a class="headerlink" href="#id10" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div style='clear:both'></div></section>
<section id="transparency-examples">
<span id="sphx-glr-sphinx-gallery-auto-transparency"></span><span id="id4"></span><h1>Transparency Examples<a class="headerlink" href="#transparency-examples" title="Permalink to this headline">¶</a></h1>
<p>Here you can find various examples of how to use FAT Forensics to explain and
interpret data sets, machine learning models and their predictions.</p>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use a tabular surrogate tree-based explainer to explain a predi..."><figure class="align-center" id="id11">
<img alt="../_images/sphx_glr_xmpl_transparency_tree_thumb.png" src="../_images/sphx_glr_xmpl_transparency_tree_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="transparency/xmpl_transparency_tree.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-tree-py"><span class="std std-ref">Using a Surrogate Tree Explainer</span></a></span><a class="headerlink" href="#id11" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the LIME tabular explainer to explain a prediction."><figure class="align-center" id="id12">
<img alt="../_images/sphx_glr_xmpl_transparency_lime_thumb.png" src="../_images/sphx_glr_xmpl_transparency_lime_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="transparency/xmpl_transparency_lime.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-lime-py"><span class="std std-ref">Using LIME Explainer</span></a></span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the Partial Dependence (PD) explainer and its plotting func..."><figure class="align-center" id="id13">
<img alt="../_images/sphx_glr_xmpl_transparency_pd_thumb.png" src="../_images/sphx_glr_xmpl_transparency_pd_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="transparency/xmpl_transparency_pd.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-pd-py"><span class="std std-ref">Using Partial Dependence Explainer</span></a></span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the LIME image explainer to explain a prediction."><figure class="align-center" id="id14">
<img alt="../_images/sphx_glr_xmpl_transparency_lime_image_thumb.png" src="../_images/sphx_glr_xmpl_transparency_lime_image_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="transparency/xmpl_transparency_lime_image.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-lime-image-py"><span class="std std-ref">Using LIME Image Explainer</span></a></span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the Data Description to interpret a data set. (See the :mod..."><figure class="align-center" id="id15">
<img alt="../_images/sphx_glr_xmpl_transparency_data_desc_thumb.png" src="../_images/sphx_glr_xmpl_transparency_data_desc_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="transparency/xmpl_transparency_data_desc.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-data-desc-py"><span class="std std-ref">Using Data Description Explainer</span></a></span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the Counterfactual Prediction explainer (:class:`fatf.trans..."><figure class="align-center" id="id16">
<img alt="../_images/sphx_glr_xmpl_transparency_cf_thumb.png" src="../_images/sphx_glr_xmpl_transparency_cf_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="transparency/xmpl_transparency_cf.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-cf-py"><span class="std std-ref">Using Counterfactual Prediction Explainer</span></a></span><a class="headerlink" href="#id16" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how to use the Individual Conditional Expectation explainer and its pl..."><figure class="align-center" id="id17">
<img alt="../_images/sphx_glr_xmpl_transparency_ice_thumb.png" src="../_images/sphx_glr_xmpl_transparency_ice_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="transparency/xmpl_transparency_ice.html#sphx-glr-sphinx-gallery-auto-transparency-xmpl-transparency-ice-py"><span class="std std-ref">Using Individual Conditional Expectation Explainer</span></a></span><a class="headerlink" href="#id17" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</div><div class="toctree-wrapper compound">
</div>
<div style='clear:both'></div><div class="sphx-glr-footer class sphx-glr-footer-gallery docutils container">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/34807197e900067e97fe61eaa989900a/sphinx_gallery_auto_python.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">sphinx_gallery_auto_python.zip</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/1830246094ab44475e07227dc8dc0552/sphinx_gallery_auto_jupyter.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Jupyter</span> <span class="pre">notebooks:</span> <span class="pre">sphinx_gallery_auto_jupyter.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


          </div>
        </div>
      </div>
        </div>
      </div>
    </div>
  </div>
</div>

  <div class="container cusotm-footer">
    <div class="row">
      <div class="col-3">
        &copy; 2018--2023, Kacper Sokol et al.
      </div>
      <div class="col-6">
        <a class="footer-img-link" href="contributors.html#funding">
          <img src="../_static/img/bristol.svg" title="Univeristy of Bristol" style="max-height: 30px">
          &nbsp;
          <img src="../_static/img/thales.svg" title="Thales" style="max-height: 20px">
        </a>
        <br>
        <a href="contributors.html#funding" style="top: 4px; position: relative;">
          More information on our contributors
        </a>
      </div>
      <div class="col-3">
        <a href="../_sources/sphinx_gallery_auto/index.rst.txt" rel="nofollow">
          Show this page source
        </a>
      </div>
    </div>
  </div>

  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-FHEM8Y8CHX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-FHEM8Y8CHX');
  </script>
  

  
  <script>
    (function() {
      var cx = '014039732624725851926:mpducezglrq';
      var gcse = document.createElement('script');
      gcse.type = 'text/javascript';
      gcse.async = true;
      gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(gcse, s);
    })();
  </script>
  
  </body>
</html>